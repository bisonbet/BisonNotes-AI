<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Journal - Complete User Guide</title>
    <style>
        /* Minimal theme-friendly styles that adapt to any WordPress theme */
        .audio-journal-guide {
            /* Inherit theme's font and colors */
            line-height: 1.6;
            width: 100%;
            max-width: none;
            margin: 0 auto;
            padding: 0.5em;
            box-sizing: border-box;
        }
        
        /* Use theme's existing heading styles */
        .audio-journal-guide h1 {
            margin-bottom: 1em;
            border-bottom: 2px solid currentColor;
            padding-bottom: 0.5em;
        }
        
        .audio-journal-guide h2 {
            margin-top: 2em;
            margin-bottom: 1em;
            padding: 0.5em 1em;
            background: rgba(0,0,0,0.05);
            border-left: 4px solid currentColor;
            border-radius: 4px;
        }
        
        .audio-journal-guide h3 {
            margin-top: 1.5em;
            margin-bottom: 0.8em;
            border-left: 3px solid currentColor;
            padding-left: 1em;
        }
        
        .audio-journal-guide h4 {
            margin-top: 1.2em;
            margin-bottom: 0.6em;
            font-weight: 600;
        }
        
        /* Inherit theme's list styles */
        .audio-journal-guide ul, .audio-journal-guide ol {
            margin-bottom: 1.5em;
        }
        
        .audio-journal-guide li {
            margin-bottom: 0.5em;
        }
        
        /* Use theme's code styling */
        .audio-journal-guide code {
            background: rgba(0,0,0,0.05);
            padding: 2px 6px;
            border-radius: 3px;
            font-family: monospace;
        }
        
        .audio-journal-guide pre {
            background: rgba(0,0,0,0.05);
            padding: 1em;
            border-radius: 4px;
            overflow-x: auto;
            margin: 1em 0;
        }
        
        .audio-journal-guide pre code {
            background: none;
            padding: 0;
        }
        
        /* Theme-adaptive boxes */
        .audio-journal-guide .info-box {
            background: rgba(0,0,0,0.03);
            border: 1px solid rgba(0,0,0,0.1);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        .audio-journal-guide .success-box {
            background: rgba(0,128,0,0.05);
            border: 1px solid rgba(0,128,0,0.2);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        .audio-journal-guide .warning-box {
            background: rgba(255,165,0,0.05);
            border: 1px solid rgba(255,165,0,0.2);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        /* Step list with minimal styling */
        .audio-journal-guide .step-list {
            counter-reset: step-counter;
            list-style: none;
            padding-left: 0;
        }
        
        .audio-journal-guide .step-list li {
            counter-increment: step-counter;
            margin-bottom: 1em;
            padding: 1em;
            background: rgba(0,0,0,0.02);
            border-radius: 6px;
            border-left: 3px solid currentColor;
        }
        
        .audio-journal-guide .step-list li::before {
            content: counter(step-counter);
            background: currentColor;
            color: white;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 0.5em;
            font-size: 0.9em;
        }
        
        /* Responsive grid that adapts to theme */
        .audio-journal-guide .engine-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5em;
            margin: 2em 0;
        }
        
        .audio-journal-guide .engine-card {
            background: rgba(0,0,0,0.02);
            border: 1px solid rgba(0,0,0,0.1);
            border-radius: 8px;
            padding: 1.5em;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }
        
        .audio-journal-guide .engine-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .audio-journal-guide .engine-card h4 {
            margin-top: 0;
            border-bottom: 1px solid rgba(0,0,0,0.1);
            padding-bottom: 0.5em;
        }
        
        /* Theme-adaptive badges */
        .audio-journal-guide .engine-type {
            display: inline-block;
            padding: 0.25em 0.75em;
            border-radius: 12px;
            font-size: 0.8em;
            font-weight: bold;
            margin-bottom: 0.5em;
            margin-right: 0.5em;
        }
        
        .audio-journal-guide .type-local {
            background: rgba(0,128,0,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-cloud {
            background: rgba(0,0,255,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-free {
            background: rgba(255,165,0,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-paid {
            background: rgba(255,0,0,0.1);
            color: inherit;
        }
        
        /* Table styling that adapts to theme */
        .audio-journal-guide table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5em 0;
            background: rgba(0,0,0,0.02);
            border-radius: 8px;
            overflow: hidden;
        }
        
        .audio-journal-guide th {
            background: rgba(0,0,0,0.1);
            padding: 0.75em;
            text-align: left;
            font-weight: 600;
        }
        
        .audio-journal-guide td {
            padding: 0.75em;
            border-bottom: 1px solid rgba(0,0,0,0.05);
        }
        
        .audio-journal-guide tr:hover {
            background: rgba(0,0,0,0.02);
        }
        
        /* Table of contents */
        .audio-journal-guide .toc {
            background: rgba(0,0,0,0.02);
            padding: 1.5em;
            border-radius: 8px;
            margin: 2em 0;
            border-left: 3px solid currentColor;
        }
        
        .audio-journal-guide .toc h3 {
            margin-top: 0;
        }
        
        .audio-journal-guide .toc ul {
            list-style: none;
            padding-left: 0;
        }
        
        .audio-journal-guide .toc li {
            margin-bottom: 0.5em;
        }
        
        .audio-journal-guide .toc a {
            text-decoration: none;
            font-weight: 500;
        }
        
        .audio-journal-guide .toc a:hover {
            text-decoration: underline;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .audio-journal-guide .engine-grid {
                grid-template-columns: 1fr;
            }
            
            .audio-journal-guide h1 {
                font-size: 1.8em;
            }
            
            .audio-journal-guide h2 {
                font-size: 1.4em;
            }
        }
    </style>
</head>
<body>
    <div class="audio-journal-guide">
        <h1>üéôÔ∏è BisonNotes AI - Complete User Guide</h1>
        
        <p>Welcome to BisonNotes AI! This comprehensive guide will walk you through every aspect of using the app, from basic recording to advanced AI configuration.</p>
        
        <!-- Recent Updates Section - Add content here when needed
        <div class="info-box">
            <h3>üÜï Recent Updates</h3>
            <h4>Update Title (Date)</h4>
            <ul>
                <li><strong>Feature</strong>: Description</li>
            </ul>
        </div>
        -->
        
        <div class="toc">
            <h3>üìã Table of Contents</h3>
            <ul>
                <li><a href="#getting-started">üì± Getting Started</a></li>
                <li><a href="#recording-features">üéôÔ∏è Recording Features</a>
                    <ul style="margin-left: 1.5em; margin-top: 0.5em;">
                        <li><a href="#combining-recordings">Combining Recordings</a></li>
                    </ul>
                </li>
                <li><a href="#ai-engine-configuration">ü§ñ AI Engine Configuration</a></li>
                <li><a href="#transcription-configuration">üìù Transcription Configuration</a></li>
                <li><a href="#working-with-summaries">üìä Working with Summaries</a></li>
                <li><a href="#audio-playback">üéµ Audio Playback</a></li>
                <li><a href="#settings-configuration">‚öôÔ∏è Settings & Configuration</a>
                    <ul style="margin-left: 1.5em; margin-top: 0.5em;">
                        <li><a href="#simple-vs-advanced-settings">Simple Settings vs Advanced Settings</a></li>
                    </ul>
                </li>
                <li><a href="#troubleshooting">üîß Troubleshooting</a></li>
                <li><a href="#advanced-features">üì± Advanced Features</a></li>
                <li><a href="#best-practices">üéØ Best Practices</a></li>
                <li><a href="#external-resources">üîó External Resources</a></li>
            </ul>
        </div>

        <h2 id="getting-started">üì± Getting Started</h2>

        <h3>First Launch Setup</h3>
        <ol class="step-list">
            <li><strong>Install the App</strong>: Download BisonNotes AI from the App Store</li>
            <li><strong>Simple Settings Welcome Screen</strong>: Upon first launch, you'll see a streamlined setup screen with three main options:
                <div class="info-box">
                    <h4>üéØ Initial Setup Options</h4>
                    <ul>
                        <li><strong>OpenAI (Cloud)</strong>: 
                            <ul>
                                <li>Cloud-based transcription and AI summaries</li>
                                <li>Requires OpenAI API key (enter during setup)</li>
                                <li>Most powerful and capable option</li>
                                <li>Pay-per-use pricing</li>
                                <li>Best for: High-quality results, advanced features</li>
                            </ul>
                        </li>
                        <li><strong>On-Device AI</strong>:
                            <ul>
                                <li>Private, on-device AI processing</li>
                                <li>No data leaves your device</li>
                                <li>Best for recordings under 60 minutes</li>
                                <li>Requires download of AI and Transcription models (5GB)</li>
                                <li>May be less accurate than cloud services</li>
                                <li>After selecting, you'll be taken to download AI models</li>
                                <li>Device requirements: Transcription requires iPhone 12+; AI Summary requires iPhone 15 Pro or iPhone 16+</li>
                            </ul>
                        </li>
                        <li><strong>Advanced & Other Options</strong>:
                            <ul>
                                <li>Skip initial setup and configure later</li>
                                <li>Access to all available engines:
                                    <ul>
                                        <li>OpenAI Compatible - Use LiteLLM, llama.cpp, or similar proxies</li>
                                        <li>Google AI Studio - Advanced Gemini AI processing</li>
                                        <li>AWS Bedrock - Enterprise-grade Claude AI</li>
                                        <li>Mistral AI - Advanced AI processing with Mistral models</li>
                                    </ul>
                                </li>
                                <li>Selecting this option immediately opens the advanced settings page</li>
                            </ul>
                        </li>
                    </ul>
                    <p><strong>üí° Tip</strong>: The simple settings page automatically detects your current configuration. If you've configured something in advanced settings that doesn't match the simple options, it will automatically show "Advanced & Other Options".</p>
                </div>
            </li>
            <li><strong>Location Permission</strong>: The app will ask for location access if you enabled location tracking:
                <ul>
                    <li><strong>"Allow While Using App"</strong>: Recommended - captures location during recording</li>
                    <li><strong>"Don't Allow"</strong>: You can still manually add locations later</li>
                </ul>
            </li>
            <li><strong>Automatic Migration</strong>: On first launch, the app will automatically scan for any existing audio files and migrate them into the database</li>
        </ol>

        <h3>Your First Recording</h3>
        <ol class="step-list">
            <li><strong>Start Recording</strong>: Tap the large microphone button on the main screen</li>
            <li><strong>Microphone Permission</strong>: On your first recording, iOS will ask for microphone access:
                <ul>
                    <li><strong>Tap "OK"</strong>: Required for the app to function</li>
                    <li>If denied, you can re-enable it in Settings ‚Üí Privacy & Security ‚Üí Microphone</li>
                </ul>
            </li>
            <li><strong>Recording Status</strong>: You'll see:
                <ul>
                    <li>Red recording indicator</li>
                    <li>Live timer showing duration</li>
                    <li>Location indicator (if location services enabled)</li>
                </ul>
            </li>
            <li><strong>Stop Recording</strong>: Tap the stop button to end recording</li>
            <li><strong>Background Recording</strong>: The app continues recording even when minimized or phone is locked</li>
        </ol>

        <h3>Generate Your First Transcript</h3>
        <ol class="step-list">
            <li><strong>Access Recording</strong>: After stopping your recording, you'll see it in the main recordings list</li>
            <li><strong>Start Transcription</strong>: 
                <ul>
                    <li>Tap on your recording to open the detail view</li>
                    <li>Tap the "Generate Transcript" button</li>
                    <li>The app will process your audio using your selected AI engine</li>
                </ul>
            </li>
            <li><strong>Transcription Progress</strong>: You'll see a progress indicator showing:
                <ul>
                    <li>Processing status</li>
                    <li>Time remaining estimate</li>
                    <li>You can continue using the app while it processes in the background</li>
                </ul>
            </li>
            <li><strong>View Results</strong>: Once complete, you'll see the full transcript with:
                <ul>
                    <li>Editable text</li>
                    <li>Time stamps (if supported by your AI engine)</li>
                    <li>Confidence indicators</li>
                </ul>
            </li>
        </ol>

        <h3>Generate Your First Summary</h3>
        <ol class="step-list">
            <li><strong>Prerequisites</strong>: You must have a transcript before generating a summary</li>
            <li><strong>Access Summary Options</strong>: In the recording detail view, tap "Generate Summary"</li>
            <li><strong>AI Processing</strong>: The app will analyze your transcript and create:
                <ul>
                    <li><strong>Enhanced Summary</strong>: Main content overview</li>
                    <li><strong>Action Items</strong>: Extracted tasks with priority levels</li>
                    <li><strong>Reminders</strong>: Time-sensitive items with urgency indicators</li>
                    <li><strong>Alternative Titles</strong>: AI-generated recording names</li>
                </ul>
            </li>
            <li><strong>Review Results</strong>: The summary view shows:
                <ul>
                    <li>Expandable sections for each content type</li>
                    <li>Visual priority and confidence indicators</li>
                    <li>Interactive maps (if location data available)</li>
                    <li>Integration options for tasks and reminders</li>
                </ul>
            </li>
        </ol>

        <h3>iCloud Sync Setup</h3>
        <div class="info-box">
            <p><strong>üîÑ When Does This Appear?</strong> After generating your first successful summary, the app will prompt you about iCloud syncing.</p>
        </div>
        <ol class="step-list">
            <li><strong>iCloud Prompt</strong>: You'll see a dialog asking about iCloud sync for summaries</li>
            <li><strong>Choose Your Option</strong>:
                <ul>
                    <li><strong>"Enable iCloud Sync"</strong>: Summaries sync across all your devices
                        <ul>
                            <li>Requires iCloud to be enabled on your device</li>
                            <li>Uses your iCloud storage quota</li>
                            <li>Provides backup and cross-device access</li>
                        </ul>
                    </li>
                    <li><strong>"Keep Local Only"</strong>: Summaries stay on this device only
                        <ul>
                            <li>No cloud storage used</li>
                            <li>Better for privacy-sensitive content</li>
                            <li>Can be changed later in Settings</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Configuration</strong>: If you enable iCloud, the app will automatically configure CloudKit sync</li>
        </ol>

        <h3>Managing and Deleting Recordings</h3>
        <ol class="step-list">
            <li><strong>Access Recording Options</strong>: 
                <ul>
                    <li>Long press on any recording in the main list</li>
                    <li>Or tap the recording and look for the "..." menu</li>
                </ul>
            </li>
            <li><strong>Deletion Options</strong>: When you tap "Delete", you'll see comprehensive options:
                <div class="info-box">
                    <h4>üóëÔ∏è What Gets Deleted?</h4>
                    <ul>
                        <li><strong>Audio File Only</strong>: Keeps transcript and summary, removes audio
                            <ul>
                                <li>Best for: Saving storage while keeping the processed content</li>
                                <li>Note: You can't regenerate transcript or play audio after this</li>
                            </ul>
                        </li>
                        <li><strong>Everything</strong>: Removes audio file, transcript, and summary
                            <ul>
                                <li>Complete removal from device and iCloud (if syncing)</li>
                                <li>Cannot be undone</li>
                            </ul>
                        </li>
                        <li><strong>Summary Only</strong>: Keeps audio and transcript, removes AI-generated summary
                            <ul>
                                <li>Useful if you want to regenerate summary with different AI engine</li>
                                <li>Can regenerate summary anytime</li>
                            </ul>
                        </li>
                    </ul>
                    <p><strong>‚ö†Ô∏è Important</strong>: Deletion is permanent. Make sure you have backups if needed.</p>
                </div>
            </li>
            <li><strong>Confirmation</strong>: The app will ask you to confirm the deletion to prevent accidents</li>
            <li><strong>Background Cleanup</strong>: After deletion, the app automatically:
                <ul>
                    <li>Removes files from device storage</li>
                    <li>Updates iCloud sync (if enabled)</li>
                    <li>Cleans up any orphaned data</li>
                    <li>Updates the recordings list</li>
                </ul>
            </li>
        </ol>

        <h2 id="recording-features">üéôÔ∏è Recording Features</h2>

        <h3>Location Tracking</h3>
        <ul>
            <li><strong>Automatic</strong>: GPS location is captured with each recording</li>
            <li><strong>Manual</strong>: Add or edit location later in summary view</li>
            <li><strong>Privacy</strong>: Location tracking can be disabled in settings</li>
        </ul>

        <h3>Import Existing Audio</h3>
        <ol class="step-list">
            <li>Tap "Import Audio Files" on the main screen</li>
            <li>Select audio files from your device</li>
            <li>Files are automatically added to your recordings library</li>
        </ol>

        <h3 id="combining-recordings">Combining Recordings</h3>
        <div class="info-box">
            <p><strong>üîó When to Combine</strong>: Use this feature to merge two separate recordings into one continuous file. This is especially useful if your recording was interrupted (e.g., microphone disconnected) and you want to create a single combined recording.</p>
        </div>
        <ol class="step-list">
            <li><strong>Access Recordings List</strong>: 
                <ul>
                    <li>Go to the "Recordings" tab</li>
                    <li>Tap "Select" button in the top right</li>
                </ul>
            </li>
            <li><strong>Select Two Recordings</strong>:
                <ul>
                    <li>Tap the checkbox next to the first recording you want to combine</li>
                    <li>Tap the checkbox next to the second recording</li>
                    <li>You can only select two recordings at a time</li>
                </ul>
            </li>
            <li><strong>Combine Recordings</strong>:
                <ul>
                    <li>Once two recordings are selected, a "Combine" button appears</li>
                    <li>Tap "Combine" to open the combination interface</li>
                </ul>
            </li>
            <li><strong>Choose Recording Order</strong>:
                <div class="info-box">
                    <h4>üìã Order Selection</h4>
                    <ul>
                        <li>The app automatically recommends which recording should be first based on recording dates</li>
                        <li>You'll see a "Recommended" badge on the suggested first recording</li>
                        <li>Tap the "First" recording card to swap the order if needed</li>
                        <li>The preview shows the total combined duration</li>
                    </ul>
                </div>
            </li>
            <li><strong>Important Requirements</strong>:
                <div class="warning-box">
                    <h4>‚ö†Ô∏è Before Combining</h4>
                    <p><strong>Recordings with transcripts or summaries cannot be combined.</strong> You must delete any existing transcripts and/or summaries from both recordings before combining them.</p>
                    <ul>
                        <li>If either recording has a transcript, you'll see a message explaining which recording has a transcript</li>
                        <li>If either recording has a summary, you'll see a message explaining which recording has a summary</li>
                        <li>Delete the transcripts/summaries from both recordings, then try combining again</li>
                    </ul>
                    <p><strong>Why?</strong> Transcripts and summaries are tied to specific audio files. When combining recordings, you'll need to regenerate transcripts and summaries for the new combined file.</p>
                </div>
            </li>
            <li><strong>Complete the Combination</strong>:
                <ul>
                    <li>Review the combined duration preview</li>
                    <li>Tap "Combine Recordings" to merge the files</li>
                    <li>The app will create a new combined recording file</li>
                    <li>The original recordings remain unchanged</li>
                </ul>
            </li>
            <li><strong>After Combining</strong>:
                <ul>
                    <li>The new combined recording appears in your recordings list</li>
                    <li>You can generate a new transcript for the combined recording</li>
                    <li>You can generate a new summary for the combined recording</li>
                    <li>The original two recordings remain available if you need them</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Tips for Combining Recordings</h4>
            <ul>
                <li><strong>Best Use Case</strong>: Combining recordings that were split due to microphone disconnection or app interruption</li>
                <li><strong>Order Matters</strong>: Make sure the recordings are in the correct chronological order</li>
                <li><strong>Storage</strong>: The combined file will be the sum of both original file sizes</li>
                <li><strong>Processing</strong>: After combining, you'll need to generate new transcripts and summaries for the combined recording</li>
            </ul>
        </div>

        <h2 id="ai-engine-configuration">ü§ñ AI Engine Configuration</h2>

        <div class="info-box">
            <h3>Overview</h3>
            <p>BisonNotes AI supports multiple AI engines for transcription and summarization. Each has different capabilities and requirements.</p>
        </div>

        <div class="engine-grid">
            <div class="engine-card">
                <h4>1. On-Device LLM</h4>
                <span class="engine-type type-local">On-device</span>
                <span class="engine-type type-free">Free</span>
                <p><strong>Type</strong>: On-device AI processing using local LLM models<br>
                <strong>Cost</strong>: Free<br>
                <strong>Privacy</strong>: 100% local<br>
                <strong>Internet</strong>: Required only for initial model download<br>
                <strong>Requirements</strong>:
                    <ul>
                        <li><strong>Transcription</strong>: iPhone 12 or newer, or iPads with M1+ or A17 Pro chips</li>
                        <li><strong>AI Summary</strong>: iPhone 15 Pro, iPhone 16 or newer</li>
                        <li>iOS 18.1+</li>
                    </ul>
                </p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Select "On-Device AI" in simple settings</li>
                        <li>Download one or more AI summary models</li>
                        <li>Uses Apple Transcription for transcription</li>
                        <li>Uses downloaded LLM models for AI summaries</li>
                    </ul>
                </p>
                <p><strong>Available Models</strong>:
                    <ul>
                        <li><strong>Gemma 3n E4B</strong> (Default): 3.09 GB download, 32K context</li>
                        <li><strong>Qwen3 4B</strong>: 2.72 GB download, 32K context</li>
                        <li><strong>Phi-4 Mini</strong>: 2.49 GB download, 16K context</li>
                        <li><strong>Ministral 3B</strong>: ~2.15 GB download, 32K context</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Privacy-conscious users, offline use, recordings under 60 minutes</p>
                <p><strong>Limitations</strong>:
                    <ul>
                        <li>Best for recordings under 60 minutes</li>
                        <li>Requires 2-3GB storage per model</li>
                        <li>May be less accurate than cloud services</li>
                    </ul>
                </p>
            </div>

            <div class="engine-card">
                <h4>2. OpenAI Integration</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Pay-per-use (very affordable)<br>
                <strong>Privacy</strong>: Data sent to OpenAI<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Best for</strong>: High-quality results, advanced features</p>
            </div>

            <div class="engine-card">
                <h4>3. Google AI Studio</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-free">Free tier</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Free tier available, then pay-per-use<br>
                <strong>Privacy</strong>: Data sent to Google<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Best for</strong>: Balanced performance and cost</p>
            </div>

            <div class="engine-card">
                <h4>4. OpenAI API Compatible</h4>
                <span class="engine-type type-cloud">Cloud/Local</span>
                <span class="engine-type type-free">Flexible</span>
                <p><strong>Type</strong>: OpenAI-compatible API endpoint<br>
                <strong>Cost</strong>: Varies by provider<br>
                <strong>Privacy</strong>: Depends on provider<br>
                <strong>Internet</strong>: Required (unless local server)</p>
                <p><strong>Supported Providers</strong>: This single engine option works with multiple providers:
                    <ul>
                        <li><strong>LiteLLM</strong>: Open-source proxy for multiple providers</li>
                        <li><strong>llama.cpp</strong>: High-performance local LLM inference server</li>
                        <li><strong>Nebius</strong>: Cloud provider with OpenAI-compatible API</li>
                        <li><strong>Groq</strong>: Fast inference with OpenAI-compatible API</li>
                        <li><strong>Custom Servers</strong>: Any OpenAI-compatible endpoint</li>
                    </ul>
                </p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI API Compatible</li>
                        <li>Enter your API key (from your chosen provider, or use "no-key" for local servers)</li>
                        <li>Set base URL to your provider's endpoint:
                            <ul>
                                <li>Groq: <code>https://api.groq.com/v1</code></li>
                                <li>Nebius: Your Nebius endpoint URL</li>
                                <li>LiteLLM: Your LiteLLM server URL</li>
                                <li>llama.cpp: Your llama.cpp server URL (default: <code>http://localhost:8080</code>)</li>
                            </ul>
                        </li>
                        <li>Select model (use your provider's model name)</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Using LiteLLM, llama.cpp, Nebius, Groq, or other OpenAI-compatible services</p>
            </div>

            <div class="engine-card">
                <h4>5. Mistral AI</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI processing<br>
                <strong>Cost</strong>: Pay-per-use<br>
                <strong>Privacy</strong>: Data sent to Mistral AI<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí Mistral AI</li>
                        <li>Enter your Mistral API key</li>
                        <li>Select model (Mistral Medium, Large, etc.)</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Fast, high-quality summaries using Mistral's optimized models</p>
            </div>

            <div class="engine-card">
                <h4>6. AWS Bedrock</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Pay-per-use<br>
                <strong>Privacy</strong>: Data sent to AWS<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Best for</strong>: Enterprise features</p>
            </div>

            <div class="engine-card">
                <h4>7. Ollama</h4>
                <span class="engine-type type-local">Local AI</span>
                <span class="engine-type type-free">Free</span>
                <p><strong>Type</strong>: Local LLM server<br>
                <strong>Cost</strong>: Free (requires your own server)<br>
                <strong>Privacy</strong>: 100% local<br>
                <strong>Internet</strong>: Not required for processing</p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Install Ollama server on your local machine or network</li>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí Ollama</li>
                        <li>Set server URL (default: <code>http://localhost</code>)</li>
                        <li>Set port (default: 11434)</li>
                        <li>Select model (llama2:7b, qwen3:30b, etc.)</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Privacy, customizable models, offline use</p>
            </div>

        </div>

        <h3>Setup Instructions for Each Engine</h3>

        <h4>OpenAI Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://platform.openai.com" target="_blank">platform.openai.com</a></li>
            <li><strong>Create Account</strong>: Sign up for an OpenAI account</li>
            <li><strong>Generate API Key</strong>: Go to API Keys section and create a new key</li>
            <li><strong>Configure in App</strong>: 
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI</li>
                    <li>Enter your API key</li>
                    <li>Select your preferred model</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>Available OpenAI Models</h4>
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Type</th>
                    <th>Best For</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>GPT-4.1</strong></td>
                    <td>Summarization</td>
                    <td>Most powerful, best quality</td>
                </tr>
                <tr>
                    <td><strong>GPT-4.1 Mini</strong></td>
                    <td>Summarization</td>
                    <td>Fast and economical</td>
                </tr>
                <tr>
                    <td><strong>GPT-4.1 Nano</strong></td>
                    <td>Summarization</td>
                    <td>Fastest and most economical</td>
                </tr>

            </tbody>
        </table>

        <h4>Google AI Studio Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://aistudio.google.com" target="_blank">aistudio.google.com</a></li>
            <li><strong>Create Account</strong>: Sign up for Google AI Studio</li>
            <li><strong>Generate API Key</strong>: Create a new API key</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Google AI Studio</li>
                    <li>Enter your API key</li>
                    <li>Select model (Gemini 2.5 Flash or Flash Lite)</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>OpenAI API Compatible Integration</h4>
        <div class="info-box">
            <h4>üìå Important Note</h4>
            <p><strong>OpenAI API Compatible is a single engine option</strong> that works with multiple providers. You don't select Nebius, Groq, LiteLLM, or vLLM as separate engines - instead, you configure the "OpenAI API Compatible" option with your chosen provider's settings.</p>
        </div>
        <ol class="step-list">
            <li><strong>Choose Your Provider</strong>: Select one of these OpenAI-compatible services:
                <ul>
                    <li><strong>LiteLLM</strong>: Open-source proxy for multiple providers
                        <ul>
                            <li>Base URL: Your LiteLLM server URL (e.g., <code>http://localhost:4000/v1</code>)</li>
                            <li>Get API key from your LiteLLM configuration</li>
                            <li>Documentation: <a href="https://github.com/BerriAI/litellm" target="_blank">github.com/BerriAI/litellm</a></li>
                        </ul>
                    </li>
                    <li><strong>llama.cpp</strong>: High-performance local LLM inference server
                        <ul>
                            <li>Base URL: Your llama.cpp server URL (default: <code>http://localhost:8080</code>)</li>
                            <li>API key: Use "no-key" or leave empty for local servers</li>
                            <li>Installation: Clone from <a href="https://github.com/ggerganov/llama.cpp" target="_blank">github.com/ggerganov/llama.cpp</a>, build with <code>make</code>, then run <code>./server --model &lt;model_file&gt;</code></li>
                            <li>Documentation: See <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp README</a> for full setup instructions</li>
                            <li>Alternative: Use <code>llama-cpp-python</code> with <code>pip install 'llama-cpp-python[server]'</code> and run <code>python3 -m llama_cpp.server --model /path/to/model.gguf</code></li>
                        </ul>
                    </li>
                    <li><strong>Nebius</strong>: Cloud provider with OpenAI-compatible API
                        <ul>
                            <li>Base URL: Your Nebius endpoint URL</li>
                            <li>Get API key from Nebius console</li>
                        </ul>
                    </li>
                    <li><strong>Groq</strong>: Fast inference with OpenAI-compatible API
                        <ul>
                            <li>Base URL: <code>https://api.groq.com/v1</code></li>
                            <li>Get API key from <a href="https://console.groq.com" target="_blank">console.groq.com</a></li>
                        </ul>
                    </li>
                    <li><strong>Custom Server</strong>: Your own OpenAI-compatible endpoint
                        <ul>
                            <li>Base URL: Your server's endpoint URL</li>
                            <li>API key: As configured on your server</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Get API Key</strong>: Obtain an API key from your chosen provider (if required)</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI API Compatible</li>
                    <li>Enter your API key (from your chosen provider)</li>
                    <li>Set base URL to your provider's endpoint (see examples above)</li>
                    <li>Select model (use your provider's exact model name, e.g., <code>llama-3.1-70b-versatile</code> for Groq)</li>
                    <li>Configure temperature and max tokens</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° OpenAI Compatible Tips</h4>
            <ul>
                <li><strong>Single Engine Option</strong>: All providers (Nebius, Groq, LiteLLM, llama.cpp) use the same "OpenAI API Compatible" engine option - just change the base URL and API key</li>
                <li><strong>Base URL Examples</strong>:
                    <ul>
                        <li>Groq: <code>https://api.groq.com/v1</code></li>
                        <li>Local llama.cpp: <code>http://localhost:8080</code> (default port)</li>
                        <li>Local LiteLLM: <code>http://localhost:4000/v1</code></li>
                        <li>Nebius: Your Nebius endpoint URL</li>
                    </ul>
                </li>
                <li><strong>Model Names</strong>: Use the exact model name your provider supports (e.g., Groq uses names like <code>llama-3.1-70b-versatile</code>, not <code>gpt-4o</code>)</li>
                <li><strong>Local Servers</strong>: For local servers (llama.cpp, LiteLLM), ensure your device can reach the server IP address</li>
                <li><strong>llama.cpp Setup</strong>: 
                    <ul>
                        <li>Native server: Clone <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp</a>, build with <code>make</code>, run <code>./server --model &lt;model.gguf&gt;</code></li>
                        <li>Python server: Install with <code>pip install 'llama-cpp-python[server]'</code>, run <code>python3 -m llama_cpp.server --model /path/to/model.gguf</code></li>
                        <li>Default port is 8080, API key can be "no-key" or empty</li>
                    </ul>
                </li>
                <li><strong>Transcription</strong>: OpenAI API Compatible is also available for transcription in Settings ‚Üí Transcription Settings</li>
            </ul>
        </div>

        <h4>Mistral AI Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://console.mistral.ai" target="_blank">console.mistral.ai</a></li>
            <li><strong>Create Account</strong>: Sign up for a Mistral AI account</li>
            <li><strong>Generate API Key</strong>: Create a new API key in your account settings</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Mistral AI</li>
                    <li>Enter your API key</li>
                    <li>Select model (Mistral Medium, Large, etc.)</li>
                    <li>Configure temperature and other parameters</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>Ollama Integration</h4>
        <ol class="step-list">
            <li><strong>Install Ollama</strong>: Visit <a href="https://ollama.com" target="_blank">ollama.com</a> and install Ollama on your local machine or server</li>
            <li><strong>Download Recommended Models</strong>:
                <pre><code>ollama pull qwen3:30b
ollama pull gpt-oss:20b
ollama pull mistral-small3.2</code></pre>
            </li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Ollama</li>
                    <li>Set server URL (default: <code>http://localhost</code> for local, or your server's IP address)</li>
                    <li>Set port (default: 11434)</li>
                    <li><strong>Run a Model Scan</strong>: Tap the refresh button to scan your Ollama server for available models</li>
                    <li>Select your preferred model:
                        <ul>
                            <li><strong>Recommended</strong>: qwen3:30b, gpt-oss:20b, mistral-small3.2</li>
                            <li>Available models will be fetched from your Ollama server</li>
                        </ul>
                    </li>
                    <li>Configure temperature and max tokens</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Ollama Tips</h4>
            <ul>
                <li><strong>Local Server</strong>: Use <code>http://localhost:11434</code> if Ollama is running on the same device</li>
                <li><strong>Network Server</strong>: Use your server's IP address (e.g., <code>http://192.168.1.100:11434</code>)</li>
                <li><strong>Model Scan</strong>: Always run a model scan after connecting to fetch the list of models installed on your Ollama server</li>
                <li><strong>Performance</strong>: Larger models provide better results but require more RAM and processing time</li>
            </ul>
        </div>

        <h4>AWS Bedrock Integration</h4>
        <ol class="step-list">
            <li><strong>AWS Account</strong>: Create an AWS account</li>
            <li><strong>Enable Bedrock</strong>: Enable AWS Bedrock service</li>
            <li><strong>Create IAM User</strong>: Create user with Bedrock permissions</li>
            <li><strong>Get Credentials</strong>: Generate access keys</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí AWS Bedrock</li>
                    <li>Enter AWS credentials</li>
                    <li>Select region</li>
                    <li>Choose foundation model</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>Whisper Integration (Local Server)</h4>
        <ol class="step-list">
            <li><strong>Install Whisper Server</strong>: 
                <pre><code># Using Docker (recommended)
docker run -d -p 9000:9000 \
  -e ASR_MODEL=base \
  -e ASR_ENGINE=openai_whisper \
  onerahmet/openai-whisper-asr-webservice:latest</code></pre>
            </li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings ‚Üí Whisper (Local Server)</li>
                    <li>Set server URL (e.g., <code>http://localhost</code> or <code>http://192.168.1.100</code>)</li>
                    <li>Set port (default: 9000)</li>
                    <li>Select protocol (REST API or Wyoming)</li>
                    <li>Select model size (tiny, base, small, medium, large-v3)</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Whisper Protocol Options</h4>
            <ul>
                <li><strong>REST API</strong>: Traditional HTTP REST API with file uploads</li>
                <li><strong>Wyoming</strong>: Modern streaming protocol with WebSocket connection</li>
            </ul>
        </div>

        <h4>AWS Transcribe Integration</h4>
        <ol class="step-list">
            <li><strong>AWS Account</strong>: Create an AWS account</li>
            <li><strong>Enable Transcribe</strong>: Enable AWS Transcribe service in your AWS console</li>
            <li><strong>Create IAM User</strong>: Create user with Transcribe permissions</li>
            <li><strong>Get Credentials</strong>: Generate access keys</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings ‚Üí AWS Transcribe</li>
                    <li>Enter AWS access key ID</li>
                    <li>Enter AWS secret access key</li>
                    <li>Select region (e.g., us-east-1, eu-west-1)</li>
                    <li>Choose language</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° AWS Transcribe Tips</h4>
            <ul>
                <li><strong>IAM Permissions</strong>: Ensure your IAM user has <code>transcribe:StartTranscriptionJob</code> and <code>transcribe:GetTranscriptionJob</code> permissions</li>
                <li><strong>Regions</strong>: Choose a region close to you for better performance</li>
                <li><strong>Cost</strong>: AWS Transcribe charges per minute of audio transcribed</li>
            </ul>
        </div>

        <h4>On-Device LLM Setup</h4>
        <ol class="step-list">
            <li><strong>Select On-Device AI</strong>: Choose "On-Device AI" in the simple settings page</li>
            <li><strong>Download Models</strong>: After saving, you'll be taken to the On-Device LLM settings page:
                <ul>
                    <li>Select one or more AI summary models to download</li>
                    <li>Available models:
                        <ul>
                            <li><strong>Gemma 3n E4B</strong> (Default): 3.09 GB, 32K context window</li>
                            <li><strong>Qwen3 4B</strong>: 2.72 GB, 32K context window</li>
                            <li><strong>Phi-4 Mini</strong>: 2.49 GB, 16K context window</li>
                            <li><strong>Ministral 3B</strong>: ~2.15 GB, 32K context window</li>
                        </ul>
                    </li>
                    <li>Download progress is shown with speed and time remaining</li>
                </ul>
            </li>
            <li><strong>Model Selection</strong>: Choose which model to use for summaries</li>
            <li><strong>Configuration</strong>: Adjust generation settings (temperature, max tokens, etc.)</li>
            <li><strong>Transcription</strong>: Uses Apple Transcription automatically (no separate configuration needed)</li>
        </ol>
        <div class="info-box">
            <h4>üíæ Storage Requirements</h4>
            <p>On-Device LLM requires 2-3GB of storage per model. Make sure you have sufficient free space before downloading models.</p>
            <h4>üì± Device Requirements</h4>
            <ul>
                <li><strong>Transcription</strong>: iPhone 12 or newer, or iPads with M1+ or A17 Pro chips</li>
                <li><strong>AI Summary</strong>: iPhone 15 Pro, iPhone 16 or newer (requires more processing power)</li>
            </ul>
        </div>

        <h2 id="transcription-configuration">üìù Transcription Configuration</h2>

        <h3>Engine Selection</h3>
        <ol class="step-list">
            <li>Go to Settings ‚Üí Transcription Settings</li>
            <li>Select your preferred transcription engine</li>
            <li>Configure the selected engine (if required)</li>
            <li>Test the connection</li>
        </ol>

        <h3>Available Transcription Engines</h3>
        <ul>
            <li><strong>Apple Transcription</strong>: On-device, no setup required, best for recordings under 60 minutes</li>
            <li><strong>OpenAI</strong>: Cloud-based, requires API key, high-quality transcription</li>
            <li><strong>Whisper (Local Server)</strong>: High-quality transcription using OpenAI's Whisper model on your local server (REST API or Wyoming protocol)</li>
            <li><strong>AWS Transcribe</strong>: Cloud-based transcription service with support for long audio files</li>
        </ul>

        <h3>Large File Processing</h3>
        <ul>
            <li><strong>Automatic Chunking</strong>: Files over 5 minutes are automatically split</li>
            <li><strong>Progress Tracking</strong>: Real-time progress updates</li>
            <li><strong>Background Processing</strong>: Continues when app is minimized</li>
            <li><strong>Timeout Settings</strong>: Configurable processing time limits</li>
        </ul>

        <h2 id="working-with-summaries">üìä Working with Summaries</h2>

        <h3>Viewing Summaries</h3>
        <ol class="step-list">
            <li>Tap the "Summaries" tab</li>
            <li>Browse your recordings with AI-generated summaries</li>
            <li>Tap any summary to view details</li>
        </ol>

        <h3>Summary Features</h3>
        <ul>
            <li><strong>Expandable Sections</strong>: Tap to expand/collapse sections</li>
            <li><strong>Task Extraction</strong>: AI-identified actionable items</li>
            <li><strong>Reminder Detection</strong>: Time-sensitive reminders</li>
            <li><strong>Priority Indicators</strong>: Color-coded task priorities</li>
            <li><strong>Location Maps</strong>: Interactive maps showing recording location</li>
        </ul>

        <h3>Editing Recording Metadata</h3>

        <h4>Changing Recording Title</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>Scroll to "Titles" section</li>
            <li>Tap "Edit" next to any title</li>
            <li>Enter new title or select from AI-generated alternatives</li>
            <li>Tap "Use This Title"</li>
        </ol>

        <h4>Setting Custom Date & Time</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>Scroll to "Recording Date & Time" section</li>
            <li>Tap "Set Custom Date & Time"</li>
            <li>Use date and time pickers</li>
            <li>Tap "Save"</li>
        </ol>

        <h4>Adding/Editing Location</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>In the location section, tap "Add Location" or "Edit Location"</li>
            <li>Choose from:
                <ul>
                    <li><strong>Current Location</strong>: Use device GPS</li>
                    <li><strong>Map Selection</strong>: Pick location on map</li>
                    <li><strong>Manual Entry</strong>: Enter coordinates manually</li>
                </ul>
            </li>
            <li>Tap "Save"</li>
        </ol>

        <h2 id="audio-playback">üéµ Audio Playback</h2>

        <h3>Basic Playback</h3>
        <ol class="step-list">
            <li>Go to "Recordings" tab</li>
            <li>Tap any recording to play</li>
            <li>Use playback controls:
                <ul>
                    <li><strong>Play/Pause</strong>: Center button</li>
                    <li><strong>Skip 15s</strong>: Side buttons</li>
                    <li><strong>Scrub</strong>: Drag progress bar</li>
                </ul>
            </li>
        </ol>

        <h3>Advanced Playback</h3>
        <ul>
            <li><strong>Seek Control</strong>: Drag the scrubber for precise positioning</li>
            <li><strong>Background Playback</strong>: Audio continues when app is minimized</li>
            <li><strong>Audio Session Management</strong>: Handles interruptions gracefully</li>
        </ul>

        <h2 id="settings-configuration">‚öôÔ∏è Settings & Configuration</h2>

        <h3 id="simple-vs-advanced-settings">Simple Settings vs Advanced Settings</h3>
        <div class="info-box">
            <h4>üéØ Understanding the Two Settings Interfaces</h4>
            <p>BisonNotes AI has two settings interfaces designed for different use cases:</p>
        </div>
        
        <h4>Simple Settings Page</h4>
        <p>The simple settings page appears on first launch and provides quick setup for the most common configurations:</p>
        <ul>
            <li><strong>Automatic Detection</strong>: The page automatically detects your current configuration:
                <ul>
                    <li>If both AI engine and transcription are set to "OpenAI" ‚Üí Shows "OpenAI" option</li>
                    <li>If AI engine is "On-Device LLM" and transcription is "Apple Transcription" ‚Üí Shows "On-Device AI" option</li>
                    <li>Any other configuration ‚Üí Automatically shows "Advanced & Other Options"</li>
                </ul>
            </li>
            <li><strong>Preserves Settings</strong>: If you manually switch to "Advanced & Other Options", your current settings are preserved (not reset to blank)</li>
            <li><strong>Quick Access</strong>: Tap "Advanced Options" button to access full settings at any time</li>
            <li><strong>Immediate Action</strong>: 
                <ul>
                    <li>Selecting "OpenAI" ‚Üí Enter API key and save</li>
                    <li>Selecting "On-Device AI" ‚Üí Saves and immediately opens On-Device LLM settings to download models</li>
                    <li>Selecting "Advanced & Other Options" ‚Üí Saves and immediately opens advanced settings page</li>
                </ul>
            </li>
        </ul>

        <h4>Advanced Settings Page</h4>
        <p>The advanced settings page provides full control over all configuration options:</p>
        <ul>
                    <li><strong>AI Processing</strong>: Configure AI summarization engines
                <ul>
                    <li>On-Device LLM</li>
                    <li>OpenAI</li>
                    <li>Google AI Studio</li>
                    <li>AWS Bedrock</li>
                    <li>Mistral AI</li>
                    <li>OpenAI API Compatible</li>
                    <li>Ollama</li>
                </ul>
            </li>
            <li><strong>Transcription Engine</strong>: Configure transcription engines
                <ul>
                    <li>Apple Transcription</li>
                    <li>OpenAI</li>
                    <li>Whisper (Local Server)</li>
                    <li>AWS Transcribe</li>
                    <li>OpenAI API Compatible</li>
                </ul>
            </li>
            <li><strong>Microphone Selection</strong>: Choose from available microphones (appears below AI and Transcription sections)</li>
            <li><strong>Preferences</strong>: Display preferences, time format, etc.</li>
            <li><strong>Advanced Settings</strong>: Location services, iCloud sync, background processing</li>
        </ul>

        <div class="info-box">
            <h4>üîÑ Switching Between Simple and Advanced</h4>
            <ul>
                <li><strong>From Simple to Advanced</strong>: Tap "Advanced Options" button in the top right</li>
                <li><strong>From Advanced to Simple</strong>: The simple settings page automatically detects your configuration when you return to it</li>
                <li><strong>Automatic Updates</strong>: If you change settings in advanced options, the simple settings page will automatically switch to "Advanced & Other Options" when you return</li>
            </ul>
        </div>

        <h3>Audio Settings</h3>
        <ul>
            <li><strong>Quality</strong>: Whisper Optimized (22 kHz, 64 kbps AAC) - Optimized for voice transcription</li>
            <li><strong>Microphone Selection</strong>: 
                <ul>
                    <li>Choose from available microphones (built-in, Bluetooth, USB devices)</li>
                    <li>Your selection is saved and used for all recordings</li>
                    <li>If selected microphone becomes unavailable, automatically falls back to iOS default</li>
                    <li>During recording, if microphone disconnects, recording continues with default microphone</li>
                </ul>
            </li>
            <li><strong>Mixed Audio</strong>: Record without interrupting system audio</li>
            <li><strong>Background Recording</strong>: Continue recording when app is minimized</li>
        </ul>

        <h3>AI Settings</h3>
        <ul>
            <li><strong>Engine Selection</strong>: Choose your preferred AI engine for summaries:
                <ul>
                    <li><strong>On-Device LLM</strong>: Privacy-focused local AI processing</li>
                    <li><strong>OpenAI</strong>: Cloud-based AI with GPT models</li>
                    <li><strong>Google AI Studio</strong>: Gemini AI processing</li>
                    <li><strong>AWS Bedrock</strong>: Enterprise-grade Claude AI</li>
                    <li><strong>Mistral AI</strong>: Advanced AI processing with Mistral models</li>
                    <li><strong>OpenAI API Compatible</strong>: Connect to OpenAI-compatible endpoints (LiteLLM, llama.cpp, Nebius, Groq, etc.)</li>
                    <li><strong>Ollama</strong>: Local LLM server for privacy-focused processing</li>
                </ul>
            </li>
            <li><strong>Model Configuration</strong>: Adjust settings for selected engine (temperature, max tokens, etc.)</li>
            <li><strong>Connection Testing</strong>: Verify API connectivity</li>
            <li><strong>Batch Regeneration</strong>: Update all summaries with new engine</li>
            <li><strong>Note</strong>: Apple Intelligence is no longer available as an AI engine option. Use On-Device LLM for local processing.</li>
        </ul>

        <h3>Background Processing</h3>
        <ul>
            <li><strong>Job Management</strong>: View active and completed jobs</li>
            <li><strong>Progress Tracking</strong>: Monitor long-running operations</li>
            <li><strong>Error Recovery</strong>: Automatic retry and error handling</li>
            <li><strong>Performance Monitoring</strong>: Real-time metrics</li>
        </ul>

        <h3>Data Management</h3>
        <ul>
            <li><strong>Migration Tools</strong>: Import legacy data</li>
            <li><strong>Database Maintenance</strong>: Clear and repair data</li>
            <li><strong>File Relationships</strong>: Manage audio, transcript, and summary files</li>
            <li><strong>Debug Tools</strong>: Advanced troubleshooting options</li>
        </ul>

        <h2 id="troubleshooting">üîß Troubleshooting</h2>

        <h3>Common Issues</h3>

        <h4>Recording Problems</h4>
        <ul>
            <li><strong>No Audio</strong>: Check microphone permissions</li>
            <li><strong>Poor Quality</strong>: Adjust audio quality settings</li>
            <li><strong>Background Recording</strong>: Enable in settings</li>
        </ul>

        <h4>AI Engine Issues</h4>
        <ul>
            <li><strong>Connection Failed</strong>: Check internet and API keys</li>
            <li><strong>Timeout Errors</strong>: Increase timeout settings</li>
            <li><strong>Authentication Errors</strong>: Verify API credentials</li>
        </ul>

        <h4>Transcription Problems</h4>
        <ul>
            <li><strong>No Transcription</strong>: Check engine configuration</li>
            <li><strong>Poor Quality</strong>: Try different engine or model</li>
            <li><strong>Large File Issues</strong>: Enable chunking for files over 5 minutes</li>
        </ul>

        <h4>Data Issues</h4>
        <ul>
            <li><strong>Missing Recordings</strong>: Use Data Migration tools</li>
            <li><strong>Corrupted Data</strong>: Clear and re-import data</li>
            <li><strong>Sync Problems</strong>: Check iCloud settings</li>
        </ul>

        <h3>Performance Optimization</h3>
        <ul>
            <li><strong>Battery Life</strong>: Use local engines for offline processing</li>
            <li><strong>Memory Usage</strong>: Close other apps during large file processing</li>
            <li><strong>Storage</strong>: Regularly clean up old recordings</li>
            <li><strong>Network</strong>: Use local engines to reduce data usage</li>
        </ul>

        <h2 id="advanced-features">üì± Advanced Features</h2>

        <h3>Background Processing</h3>
        <ul>
            <li><strong>Job Queue</strong>: Multiple operations run in background</li>
            <li><strong>Progress Tracking</strong>: Real-time updates for long operations</li>
            <li><strong>Error Recovery</strong>: Automatic retry for failed operations</li>
            <li><strong>Stale Job Cleanup</strong>: Automatic cleanup of abandoned jobs</li>
        </ul>

        <h3>File Management</h3>
        <ul>
            <li><strong>Import/Export</strong>: Support for various audio formats</li>
            <li><strong>Combining Recordings</strong>: Merge two recordings into one continuous file (see <a href="#combining-recordings">Combining Recordings</a> section)</li>
            <li><strong>File Relationships</strong>: Maintains connections between audio, transcripts, and summaries</li>
            <li><strong>Orphaned File Detection</strong>: Identifies and manages disconnected files</li>
            <li><strong>Selective Deletion</strong>: Choose what to keep when deleting recordings</li>
        </ul>

        <h3>Location Intelligence</h3>
        <ul>
            <li><strong>GPS Integration</strong>: Automatic location capture</li>
            <li><strong>Reverse Geocoding</strong>: Converts coordinates to addresses</li>
            <li><strong>Smart Location Search</strong>: Advanced search with 3-tier fallback system</li>
            <li><strong>University Database</strong>: Built-in mapping for major universities</li>
            <li><strong>Search Retry Logic</strong>: Intelligent retry for failed searches</li>
            <li><strong>Interactive Maps</strong>: View recording locations</li>
            <li><strong>Manual Location</strong>: Add locations after recording</li>
            <li><strong>Performance Optimized</strong>: Background processing prevents UI blocking</li>
        </ul>

        <h3>Data Migration</h3>
        <ul>
            <li><strong>Legacy Import</strong>: Migrate from old file-based storage</li>
            <li><strong>Data Integrity</strong>: Validate and repair data relationships</li>
            <li><strong>Batch Operations</strong>: Process multiple files at once</li>
            <li><strong>Progress Tracking</strong>: Monitor migration progress</li>
        </ul>

        <h2 id="best-practices">üéØ Best Practices</h2>

        <h3>Recording</h3>
        <ul>
            <li><strong>Environment</strong>: Record in quiet environments for best quality</li>
            <li><strong>Distance</strong>: Keep microphone 6-12 inches from mouth</li>
            <li><strong>Duration</strong>: Break long recordings into segments</li>
            <li><strong>Background</strong>: Minimize background noise</li>
        </ul>

        <h3>AI Configuration</h3>
        <ul>
            <li><strong>Privacy</strong>: Use local engines for sensitive content</li>
            <li><strong>Cost</strong>: Start with free engines, upgrade as needed</li>
            <li><strong>Quality</strong>: Experiment with different models for best results</li>
            <li><strong>Reliability</strong>: Have backup engines configured</li>
        </ul>

        <h3>Data Management</h3>
        <ul>
            <li><strong>Regular Backups</strong>: Export important recordings</li>
            <li><strong>Cleanup</strong>: Remove old recordings periodically</li>
            <li><strong>Organization</strong>: Use descriptive titles for easy finding</li>
            <li><strong>Metadata</strong>: Add location and custom dates for context</li>
        </ul>

        <h3>Performance</h3>
        <ul>
            <li><strong>Battery</strong>: Use local engines when battery is low</li>
            <li><strong>Storage</strong>: Monitor available space</li>
            <li><strong>Network</strong>: Use local engines when internet is slow</li>
            <li><strong>Memory</strong>: Close other apps during processing</li>
        </ul>

        <h2 id="external-resources">üîó External Resources</h2>

        <h3>AI Service Documentation</h3>
        <ul>
            <li><strong>OpenAI</strong>: <a href="https://platform.openai.com/docs" target="_blank">platform.openai.com/docs</a></li>
            <li><strong>Google AI</strong>: <a href="https://ai.google.dev" target="_blank">ai.google.dev</a></li>
            <li><strong>AWS Bedrock</strong>: <a href="https://docs.aws.amazon.com/bedrock" target="_blank">docs.aws.amazon.com/bedrock</a></li>
            <li><strong>AWS Transcribe</strong>: <a href="https://docs.aws.amazon.com/transcribe" target="_blank">docs.aws.amazon.com/transcribe</a></li>
        </ul>

        <h3>Additional Resources</h3>
        <ul>
            <li><strong>Mistral AI</strong>: <a href="https://docs.mistral.ai" target="_blank">docs.mistral.ai</a></li>
            <li><strong>Ollama</strong>: <a href="https://ollama.com" target="_blank">ollama.com</a></li>
            <li><strong>OpenAI API Compatible</strong>:
                <ul>
                    <li><strong>LiteLLM</strong>: <a href="https://github.com/BerriAI/litellm" target="_blank">github.com/BerriAI/litellm</a></li>
                    <li><strong>llama.cpp</strong>: <a href="https://github.com/ggerganov/llama.cpp" target="_blank">github.com/ggerganov/llama.cpp</a> - Official repository with installation and server setup instructions</li>
                    <li><strong>llama-cpp-python</strong>: <a href="https://llama-cpp-python.readthedocs.io/en/latest/server/" target="_blank">llama-cpp-python.readthedocs.io</a> - Python bindings with server support</li>
                    <li><strong>Nebius</strong>: <a href="https://nebius.com" target="_blank">nebius.com</a></li>
                    <li><strong>Groq</strong>: <a href="https://groq.com" target="_blank">groq.com</a></li>
                </ul>
            </li>
            <li><strong>Whisper</strong>: <a href="https://github.com/ahmetoner/whisper-asr-webservice" target="_blank">github.com/ahmetoner/whisper-asr-webservice</a></li>
            <li><strong>AWS Transcribe</strong>: <a href="https://aws.amazon.com/transcribe/" target="_blank">aws.amazon.com/transcribe/</a></li>
        </ul>

        <h3>Support</h3>
        <ul>
            <li><strong>GitHub Issues</strong>: Report bugs and request features</li>
            <li><strong>Documentation</strong>: Check the README for technical details</li>
            <li><strong>Community</strong>: Join discussions and share tips</li>
        </ul>

        <div class="success-box">
            <h3>üéØ Ready to Get Started?</h3>
            <p><strong>BisonNotes AI</strong> - Transform your spoken words into actionable intelligence with advanced AI processing and comprehensive data management.</p>
            <p>Download the app and start recording your first BisonNotes today!</p>
        </div>

        <hr style="margin: 3em 0; border: none; border-top: 2px solid currentColor;">

        <p style="text-align: center; font-size: 0.9em; opacity: 0.7;">
            <em>This documentation is regularly updated. For the latest information, check the app's built-in help or visit our support resources.</em>
        </p>
    </div>
</body>
</html>
