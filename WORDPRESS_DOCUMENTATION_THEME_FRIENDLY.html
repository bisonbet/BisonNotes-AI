<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Journal - Complete User Guide</title>
    <style>
        /* Override WordPress Twenty Twenty theme container constraints */
        /* Twenty Twenty sets .entry-content > * { max-width: 58rem } on ALL children */
        /* This forces children to 928px max ‚Äî we need to override it */
        .entry-content > *,
        .entry-content > .audio-journal-guide {
            max-width: none !important;
            width: 100% !important;
        }

        /* Also override the parent containers */
        .entry-content,
        .section-inner,
        .section-inner.thin,
        .section-inner.small,
        .section-inner.medium,
        .post-inner {
            max-width: none !important;
            width: calc(100% - 4rem) !important;
            box-sizing: border-box !important;
        }

        /* Minimal theme-friendly styles that adapt to any WordPress theme */
        .audio-journal-guide {
            /* Inherit theme's font and colors */
            line-height: 1.6;
            width: 100%;
            max-width: 1400px;
            margin: 0 auto;
            padding: 0.5em;
            box-sizing: border-box;
        }
        
        /* Use theme's existing heading styles */
        .audio-journal-guide h1 {
            margin-bottom: 1em;
            border-bottom: 2px solid currentColor;
            padding-bottom: 0.5em;
        }
        
        .audio-journal-guide h2 {
            margin-top: 2em;
            margin-bottom: 1em;
            padding: 0.5em 1em;
            background: rgba(0,0,0,0.05);
            border-left: 4px solid currentColor;
            border-radius: 4px;
        }
        
        .audio-journal-guide h3 {
            margin-top: 1.5em;
            margin-bottom: 0.8em;
            border-left: 3px solid currentColor;
            padding-left: 1em;
        }
        
        .audio-journal-guide h4 {
            margin-top: 1.2em;
            margin-bottom: 0.6em;
            font-weight: 600;
        }
        
        /* Inherit theme's list styles */
        .audio-journal-guide ul, .audio-journal-guide ol {
            margin-bottom: 1.5em;
        }
        
        .audio-journal-guide li {
            margin-bottom: 0.5em;
        }
        
        /* Use theme's code styling */
        .audio-journal-guide code {
            background: rgba(0,0,0,0.05);
            padding: 2px 6px;
            border-radius: 3px;
            font-family: monospace;
        }
        
        .audio-journal-guide pre {
            background: rgba(0,0,0,0.05);
            padding: 1em;
            border-radius: 4px;
            overflow-x: auto;
            margin: 1em 0;
        }
        
        .audio-journal-guide pre code {
            background: none;
            padding: 0;
        }
        
        /* Theme-adaptive boxes */
        .audio-journal-guide .info-box {
            background: rgba(0,0,0,0.03);
            border: 1px solid rgba(0,0,0,0.1);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        .audio-journal-guide .success-box {
            background: rgba(0,128,0,0.05);
            border: 1px solid rgba(0,128,0,0.2);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        .audio-journal-guide .warning-box {
            background: rgba(255,165,0,0.05);
            border: 1px solid rgba(255,165,0,0.2);
            padding: 1.5em;
            border-radius: 8px;
            margin: 1.5em 0;
        }
        
        /* Step list with minimal styling */
        .audio-journal-guide .step-list {
            counter-reset: step-counter;
            list-style: none;
            padding-left: 0;
        }
        
        .audio-journal-guide .step-list li {
            counter-increment: step-counter;
            margin-bottom: 1em;
            padding: 1em;
            background: rgba(0,0,0,0.02);
            border-radius: 6px;
            border-left: 3px solid currentColor;
        }
        
        .audio-journal-guide .step-list li::before {
            content: counter(step-counter);
            background: currentColor;
            color: white;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 0.5em;
            font-size: 0.9em;
        }
        
        /* Responsive grid that adapts to theme */
        .audio-journal-guide .engine-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5em;
            margin: 2em 0;
        }
        
        .audio-journal-guide .engine-card {
            background: rgba(0,0,0,0.02);
            border: 1px solid rgba(0,0,0,0.1);
            border-radius: 8px;
            padding: 1.5em;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }
        
        .audio-journal-guide .engine-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .audio-journal-guide .engine-card h4 {
            margin-top: 0;
            border-bottom: 1px solid rgba(0,0,0,0.1);
            padding-bottom: 0.5em;
        }
        
        /* Theme-adaptive badges */
        .audio-journal-guide .engine-type {
            display: inline-block;
            padding: 0.25em 0.75em;
            border-radius: 12px;
            font-size: 0.8em;
            font-weight: bold;
            margin-bottom: 0.5em;
            margin-right: 0.5em;
        }
        
        .audio-journal-guide .type-local {
            background: rgba(0,128,0,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-cloud {
            background: rgba(0,0,255,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-free {
            background: rgba(255,165,0,0.1);
            color: inherit;
        }
        
        .audio-journal-guide .type-paid {
            background: rgba(255,0,0,0.1);
            color: inherit;
        }
        
        /* Table styling that adapts to theme */
        .audio-journal-guide table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5em 0;
            background: rgba(0,0,0,0.02);
            border-radius: 8px;
            overflow: hidden;
        }
        
        .audio-journal-guide th {
            background: rgba(0,0,0,0.1);
            padding: 0.75em;
            text-align: left;
            font-weight: 600;
        }
        
        .audio-journal-guide td {
            padding: 0.75em;
            border-bottom: 1px solid rgba(0,0,0,0.05);
        }
        
        .audio-journal-guide tr:hover {
            background: rgba(0,0,0,0.02);
        }
        
        /* Table of contents */
        .audio-journal-guide .toc {
            background: rgba(0,0,0,0.02);
            padding: 1.5em;
            border-radius: 8px;
            margin: 2em 0;
            border-left: 3px solid currentColor;
        }
        
        .audio-journal-guide .toc h3 {
            margin-top: 0;
        }
        
        .audio-journal-guide .toc ul {
            list-style: none;
            padding-left: 0;
        }
        
        .audio-journal-guide .toc li {
            margin-bottom: 0.5em;
        }
        
        .audio-journal-guide .toc a {
            text-decoration: none;
            font-weight: 500;
        }
        
        .audio-journal-guide .toc a:hover {
            text-decoration: underline;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .entry-content,
            .post-inner,
            .section-inner,
            .page-content,
            .wp-block-post-content,
            .site-content .content-area,
            article .entry-content {
                padding-left: 1em !important;
                padding-right: 1em !important;
            }

            .audio-journal-guide .engine-grid {
                grid-template-columns: 1fr;
            }

            .audio-journal-guide h1 {
                font-size: 1.8em;
            }

            .audio-journal-guide h2 {
                font-size: 1.4em;
            }

            .audio-journal-guide table {
                display: block;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
            }
        }
    </style>
</head>
<body>
    <div class="audio-journal-guide">
        <h1>üéôÔ∏è BisonNotes AI - Complete User Guide</h1>
        
        <p>Welcome to BisonNotes AI! This comprehensive guide will walk you through every aspect of using the app, from basic recording to advanced AI configuration.</p>
        
        <div class="info-box">
            <h3>üÜï Recent Updates ‚Äî Version 1.5</h3>
            <ul>
                <li><strong>Mistral AI Transcription</strong>: New cloud transcription engine using Voxtral Mini with speaker diarization support ($0.003/min)</li>
                <li><strong>Share Extension</strong>: Import audio files directly from Voice Memos, Files, and other apps via the iOS share sheet</li>
                <li><strong>Combine Recordings</strong>: Merge two separate recordings into a single continuous audio file</li>
                <li><strong>PDF Export Redesign</strong>: Professional three-pane header with metadata, local map, and regional map views; pagination with page numbers; dedicated tasks and reminders sections</li>
                <li><strong>On-Device AI Default</strong>: On-Device AI is now the default for new installs on supported devices (6GB+ RAM)</li>
                <li><strong>Updated AI Models</strong>: Gemini 3 Pro/Flash Preview, Mistral Large 25.12, Claude Sonnet 4.5 (auto-migrated from Sonnet 4)</li>
                <li><strong>Share Extension Wake-Up</strong>: Darwin notification integration ensures the main app imports shared files immediately, even when backgrounded</li>
            </ul>
        </div>
        
        <div class="toc">
            <h3>üìã Table of Contents</h3>
            <ul>
                <li><a href="#getting-started">üì± Getting Started</a></li>
                <li><a href="#recording-features">üéôÔ∏è Recording Features</a>
                    <ul style="margin-left: 1.5em; margin-top: 0.5em;">
                        <li><a href="#action-button">iPhone Action Button Integration</a></li>
                        <li><a href="#combining-recordings">Combining Recordings</a></li>
                        <li><a href="#share-extension">Import via Share Extension</a></li>
                    </ul>
                </li>
                <li><a href="#ai-engine-configuration">ü§ñ AI Engine Configuration</a></li>
                <li><a href="#transcription-configuration">üìù Transcription Configuration</a></li>
                <li><a href="#working-with-summaries">üìä Working with Summaries</a>
                    <ul style="margin-left: 1.5em; margin-top: 0.5em;">
                        <li><a href="#search-and-filtering">Search and Filtering</a></li>
                    </ul>
                </li>
                <li><a href="#audio-playback">üéµ Audio Playback</a></li>
                <li><a href="#settings-configuration">‚öôÔ∏è Settings & Configuration</a>
                    <ul style="margin-left: 1.5em; margin-top: 0.5em;">
                        <li><a href="#simple-vs-advanced-settings">Simple Settings vs Advanced Settings</a></li>
                    </ul>
                </li>
                <li><a href="#troubleshooting">üîß Troubleshooting</a></li>
                <li><a href="#advanced-features">üì± Advanced Features</a></li>
                <li><a href="#best-practices">üéØ Best Practices</a></li>
                <li><a href="#external-resources">üîó External Resources</a></li>
            </ul>
        </div>

        <h2 id="getting-started">üì± Getting Started</h2>

        <h3>First Launch Setup</h3>
        <ol class="step-list">
            <li><strong>Install the App</strong>: Download BisonNotes AI from the App Store</li>
            <li><strong>Simple Settings Welcome Screen</strong>: Upon first launch, you'll see a streamlined setup screen with three main options:
                <div class="info-box">
                    <h4>üéØ Initial Setup Options</h4>
                    <ul>
                        <li><strong>OpenAI (Cloud)</strong>: 
                            <ul>
                                <li>Cloud-based transcription and AI summaries</li>
                                <li>Requires OpenAI API key (enter during setup)</li>
                                <li>Most powerful and capable option</li>
                                <li>Pay-per-use pricing</li>
                                <li>Best for: High-quality results, advanced features</li>
                            </ul>
                        </li>
                        <li><strong>On-Device AI</strong>:
                            <ul>
                                <li>Private, on-device AI processing</li>
                                <li>No data leaves your device</li>
                                <li>Best for recordings under 60 minutes</li>
                                <li>Requires download of AI summary models (2-3GB each) and On Device transcription model (150-520MB)</li>
                                <li>May be less accurate than cloud services</li>
                                <li>After selecting, you'll configure On Device transcription and download AI models</li>
                                <li>Device requirements: 
                                    <ul>
                                        <li>Transcription: iOS 17.0+, 4GB+ RAM (most modern devices)</li>
                                        <li>AI Summary: iPhone 15 Pro or iPhone 16+, iOS 18.1+</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                        <li><strong>Advanced & Other Options</strong>:
                            <ul>
                                <li>Skip initial setup and configure later</li>
                                <li>Access to all available engines:
                                    <ul>
                                        <li>OpenAI Compatible - Use LiteLLM, llama.cpp, or similar proxies</li>
                                        <li>Google AI Studio - Advanced Gemini AI processing</li>
                                        <li>AWS Bedrock - Enterprise-grade Claude AI</li>
                                        <li>Mistral AI - Advanced AI processing with Mistral models</li>
                                    </ul>
                                </li>
                                <li>Selecting this option immediately opens the advanced settings page</li>
                            </ul>
                        </li>
                    </ul>
                    <p><strong>üí° Tip</strong>: The simple settings page automatically detects your current configuration. If you've configured something in advanced settings that doesn't match the simple options, it will automatically show "Advanced & Other Options".</p>
                </div>
            </li>
            <li><strong>Location Permission</strong>: The app will ask for location access if you enabled location tracking:
                <ul>
                    <li><strong>"Allow While Using App"</strong>: Recommended - captures location during recording</li>
                    <li><strong>"Don't Allow"</strong>: You can still manually add locations later</li>
                </ul>
            </li>
            <li><strong>Automatic Migration</strong>: On first launch, the app will automatically scan for any existing audio files and migrate them into the database</li>
        </ol>

        <h3>Your First Recording</h3>
        <ol class="step-list">
            <li><strong>Start Recording</strong>: Tap the large microphone button on the main screen</li>
            <li><strong>Microphone Permission</strong>: On your first recording, iOS will ask for microphone access:
                <ul>
                    <li><strong>Tap "OK"</strong>: Required for the app to function</li>
                    <li>If denied, you can re-enable it in Settings ‚Üí Privacy & Security ‚Üí Microphone</li>
                </ul>
            </li>
            <li><strong>Recording Status</strong>: You'll see:
                <ul>
                    <li>Red recording indicator</li>
                    <li>Live timer showing duration</li>
                    <li>Location indicator (if location services enabled)</li>
                </ul>
            </li>
            <li><strong>Stop Recording</strong>: Tap the stop button to end recording</li>
            <li><strong>Background Recording</strong>: The app continues recording even when minimized or phone is locked</li>
        </ol>

        <h3>Generate Your First Transcript</h3>
        <ol class="step-list">
            <li><strong>Access Recording</strong>: After stopping your recording, you'll see it in the main recordings list</li>
            <li><strong>Start Transcription</strong>: 
                <ul>
                    <li>Tap on your recording to open the detail view</li>
                    <li>Tap the "Generate Transcript" button</li>
                    <li>The app will process your audio using your selected AI engine</li>
                </ul>
            </li>
            <li><strong>Transcription Progress</strong>: You'll see a progress indicator showing:
                <ul>
                    <li>Processing status</li>
                    <li>Time remaining estimate</li>
                    <li>You can continue using the app while it processes in the background</li>
                </ul>
            </li>
            <li><strong>View Results</strong>: Once complete, you'll see the full transcript with:
                <ul>
                    <li>Editable text</li>
                    <li>Time stamps (if supported by your AI engine)</li>
                    <li>Confidence indicators</li>
                </ul>
            </li>
        </ol>

        <h3>Generate Your First Summary</h3>
        <ol class="step-list">
            <li><strong>Prerequisites</strong>: You must have a transcript before generating a summary</li>
            <li><strong>Access Summary Options</strong>: In the recording detail view, tap "Generate Summary"</li>
            <li><strong>AI Processing</strong>: The app will analyze your transcript and create:
                <ul>
                    <li><strong>Enhanced Summary</strong>: Main content overview</li>
                    <li><strong>Action Items</strong>: Extracted tasks with priority levels</li>
                    <li><strong>Reminders</strong>: Time-sensitive items with urgency indicators</li>
                    <li><strong>Alternative Titles</strong>: AI-generated recording names</li>
                </ul>
            </li>
            <li><strong>Review Results</strong>: The summary view shows:
                <ul>
                    <li>Expandable sections for each content type</li>
                    <li>Visual priority and confidence indicators</li>
                    <li>Interactive maps (if location data available)</li>
                    <li>Integration options for tasks and reminders</li>
                </ul>
            </li>
        </ol>

        <h3>iCloud Sync Setup</h3>
        <div class="info-box">
            <p><strong>üîÑ When Does This Appear?</strong> After generating your first successful summary, the app will prompt you about iCloud syncing.</p>
        </div>
        <ol class="step-list">
            <li><strong>iCloud Prompt</strong>: You'll see a dialog asking about iCloud sync for summaries</li>
            <li><strong>Choose Your Option</strong>:
                <ul>
                    <li><strong>"Enable iCloud Sync"</strong>: Summaries sync across all your devices
                        <ul>
                            <li>Requires iCloud to be enabled on your device</li>
                            <li>Uses your iCloud storage quota</li>
                            <li>Provides backup and cross-device access</li>
                        </ul>
                    </li>
                    <li><strong>"Keep Local Only"</strong>: Summaries stay on this device only
                        <ul>
                            <li>No cloud storage used</li>
                            <li>Better for privacy-sensitive content</li>
                            <li>Can be changed later in Settings</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Configuration</strong>: If you enable iCloud, the app will automatically configure CloudKit sync</li>
        </ol>

        <h3>Managing and Deleting Recordings</h3>
        <ol class="step-list">
            <li><strong>Access Recording Options</strong>: 
                <ul>
                    <li>Long press on any recording in the main list</li>
                    <li>Or tap the recording and look for the "..." menu</li>
                </ul>
            </li>
            <li><strong>Deletion Options</strong>: When you tap "Delete", you'll see comprehensive options:
                <div class="info-box">
                    <h4>üóëÔ∏è What Gets Deleted?</h4>
                    <ul>
                        <li><strong>Audio File Only</strong>: Keeps transcript and summary, removes audio
                            <ul>
                                <li>Best for: Saving storage while keeping the processed content</li>
                                <li>Note: You can't regenerate transcript or play audio after this</li>
                            </ul>
                        </li>
                        <li><strong>Everything</strong>: Removes audio file, transcript, and summary
                            <ul>
                                <li>Complete removal from device and iCloud (if syncing)</li>
                                <li>Cannot be undone</li>
                            </ul>
                        </li>
                        <li><strong>Summary Only</strong>: Keeps audio and transcript, removes AI-generated summary
                            <ul>
                                <li>Useful if you want to regenerate summary with different AI engine</li>
                                <li>Can regenerate summary anytime</li>
                            </ul>
                        </li>
                    </ul>
                    <p><strong>‚ö†Ô∏è Important</strong>: Deletion is permanent. Make sure you have backups if needed.</p>
                </div>
            </li>
            <li><strong>Confirmation</strong>: The app will ask you to confirm the deletion to prevent accidents</li>
            <li><strong>Background Cleanup</strong>: After deletion, the app automatically:
                <ul>
                    <li>Removes files from device storage</li>
                    <li>Updates iCloud sync (if enabled)</li>
                    <li>Cleans up any orphaned data</li>
                    <li>Updates the recordings list</li>
                </ul>
            </li>
        </ol>

        <h2 id="recording-features">üéôÔ∏è Recording Features</h2>

        <h3 id="action-button">iPhone Action Button Integration</h3>
        <div class="info-box">
            <p><strong>üì± Available On</strong>: iPhone 15 Pro, iPhone 15 Pro Max, iPhone 16 Pro, iPhone 16 Pro Max, and future iPhone Pro models with Action Button</p>
        </div>
        <p>BisonNotes AI supports the iPhone Action Button, allowing you to quickly start recording without opening the app first. This is perfect for capturing thoughts, meetings, or voice notes instantly.</p>
        
        <h4>How to Configure the Action Button</h4>
        <ol class="step-list">
            <li><strong>Open Settings</strong>: On your iPhone, open the Settings app</li>
            <li><strong>Navigate to Action Button</strong>: Scroll down and tap "Action Button"</li>
            <li><strong>Select Shortcut</strong>: Choose "Shortcut" as the Action Button function</li>
            <li><strong>Choose BisonNotes AI</strong>: 
                <ul>
                    <li>Tap "Choose a Shortcut"</li>
                    <li>Search for "Start Recording" or "BisonNotes AI"</li>
                    <li>Select "Start Recording" from BisonNotes AI</li>
                </ul>
            </li>
            <li><strong>Done</strong>: Press the Action Button to test - it should launch BisonNotes AI and start recording automatically!</li>
        </ol>

        <h4>What Happens When You Press the Action Button</h4>
        <ul>
            <li><strong>App Opens</strong>: BisonNotes AI launches automatically (even if the app was closed)</li>
            <li><strong>Switches to Recordings Tab</strong>: The app automatically navigates to the main recording screen</li>
            <li><strong>Recording Starts Immediately</strong>: Recording begins automatically without needing to tap the microphone button</li>
            <li><strong>Background Recording</strong>: Once started, recording continues even if you switch to another app or lock your phone</li>
        </ul>

        <div class="success-box">
            <p><strong>üí° Pro Tip</strong>: The Action Button works even when your phone is locked! Press the Action Button, and BisonNotes AI will launch and start recording. This makes it perfect for quick voice notes without unlocking your phone.</p>
        </div>

        <h3>Location Tracking</h3>
        <ul>
            <li><strong>Automatic</strong>: GPS location is captured with each recording</li>
            <li><strong>Manual</strong>: Add or edit location later in summary view</li>
            <li><strong>Privacy</strong>: Location tracking can be disabled in settings</li>
        </ul>

        <h3>Import Existing Audio</h3>
        <ol class="step-list">
            <li>Tap "Import Audio Files" on the main screen</li>
            <li>Select audio files from your device</li>
            <li>Files are automatically added to your recordings library</li>
        </ol>

        <h3 id="share-extension">Import via Share Extension</h3>
        <div class="info-box">
            <p><strong>üìé Share from Other Apps</strong>: You can import audio files directly from Voice Memos, Files, and other apps using the iOS share sheet ‚Äî no need to export and re-import manually.</p>
        </div>
        <ol class="step-list">
            <li><strong>Open the Source App</strong>: Open Voice Memos, Files, or any app containing the audio file you want to import</li>
            <li><strong>Tap Share</strong>: Use the standard iOS share button and select "BisonNotes AI" from the share sheet</li>
            <li><strong>Automatic Import</strong>: The file is saved to a shared container and BisonNotes AI opens automatically to import it</li>
            <li><strong>Background Import</strong>: If BisonNotes AI is already running in the background, it will detect the new file immediately via a Darwin notification and import it without you needing to switch apps</li>
        </ol>
        <div class="info-box">
            <h4>üìã Supported File Types</h4>
            <ul>
                <li><strong>Audio</strong>: M4A, MP3, WAV, CAF, AIFF, AIF</li>
                <li><strong>Documents</strong>: TXT, MD, PDF, DOC, DOCX</li>
            </ul>
        </div>

        <h3 id="combining-recordings">Combining Recordings</h3>
        <div class="info-box">
            <p><strong>üîó When to Combine</strong>: Use this feature to merge two separate recordings into one continuous file. This is especially useful if your recording was interrupted (e.g., microphone disconnected) and you want to create a single combined recording.</p>
        </div>
        <ol class="step-list">
            <li><strong>Access Recordings List</strong>: 
                <ul>
                    <li>Go to the "Recordings" tab</li>
                    <li>Tap "Select" button in the top right</li>
                </ul>
            </li>
            <li><strong>Select Two Recordings</strong>:
                <ul>
                    <li>Tap the checkbox next to the first recording you want to combine</li>
                    <li>Tap the checkbox next to the second recording</li>
                    <li>You can only select two recordings at a time</li>
                </ul>
            </li>
            <li><strong>Combine Recordings</strong>:
                <ul>
                    <li>Once two recordings are selected, a "Combine" button appears</li>
                    <li>Tap "Combine" to open the combination interface</li>
                </ul>
            </li>
            <li><strong>Choose Recording Order</strong>:
                <div class="info-box">
                    <h4>üìã Order Selection</h4>
                    <ul>
                        <li>The app automatically recommends which recording should be first based on recording dates</li>
                        <li>You'll see a "Recommended" badge on the suggested first recording</li>
                        <li>Tap the "First" recording card to swap the order if needed</li>
                        <li>The preview shows the total combined duration</li>
                    </ul>
                </div>
            </li>
            <li><strong>Important Requirements</strong>:
                <div class="warning-box">
                    <h4>‚ö†Ô∏è Before Combining</h4>
                    <p><strong>Recordings with transcripts or summaries cannot be combined.</strong> You must delete any existing transcripts and/or summaries from both recordings before combining them.</p>
                    <ul>
                        <li>If either recording has a transcript, you'll see a message explaining which recording has a transcript</li>
                        <li>If either recording has a summary, you'll see a message explaining which recording has a summary</li>
                        <li>Delete the transcripts/summaries from both recordings, then try combining again</li>
                    </ul>
                    <p><strong>Why?</strong> Transcripts and summaries are tied to specific audio files. When combining recordings, you'll need to regenerate transcripts and summaries for the new combined file.</p>
                </div>
            </li>
            <li><strong>Complete the Combination</strong>:
                <ul>
                    <li>Review the combined duration preview</li>
                    <li>Tap "Combine Recordings" to merge the files</li>
                    <li>The app will create a new combined recording file</li>
                    <li>The original recordings remain unchanged</li>
                </ul>
            </li>
            <li><strong>After Combining</strong>:
                <ul>
                    <li>The new combined recording appears in your recordings list</li>
                    <li>You can generate a new transcript for the combined recording</li>
                    <li>You can generate a new summary for the combined recording</li>
                    <li>The original two recordings remain available if you need them</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Tips for Combining Recordings</h4>
            <ul>
                <li><strong>Best Use Case</strong>: Combining recordings that were split due to microphone disconnection or app interruption</li>
                <li><strong>Order Matters</strong>: Make sure the recordings are in the correct chronological order</li>
                <li><strong>Storage</strong>: The combined file will be the sum of both original file sizes</li>
                <li><strong>Processing</strong>: After combining, you'll need to generate new transcripts and summaries for the combined recording</li>
            </ul>
        </div>

        <h2 id="ai-engine-configuration">ü§ñ AI Engine Configuration</h2>

        <div class="info-box">
            <h3>Overview</h3>
            <p>BisonNotes AI supports multiple AI engines for transcription and summarization. Each has different capabilities and requirements.</p>
        </div>

        <div class="engine-grid">
            <div class="engine-card">
                <h4>1. On-Device AI</h4>
                <span class="engine-type type-local">On-device</span>
                <span class="engine-type type-free">Free</span>
                <p><strong>Type</strong>: On-device AI processing using local LLM models<br>
                <strong>Cost</strong>: Free<br>
                <strong>Privacy</strong>: 100% local<br>
                <strong>Internet</strong>: Required only for initial model download<br>
                <strong>Requirements</strong>:
                    <ul>
                        <li><strong>Transcription</strong>: iOS 17.0+, 4GB+ RAM (most modern iPhones and iPads)</li>
                        <li><strong>AI Summary</strong>: iPhone 15 Pro, iPhone 16 or newer, iOS 18.1+</li>
                        <li><strong>Storage</strong>: 2-3GB for AI models, 150-520MB for transcription model</li>
                    </ul>
                </p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Select "On-Device AI" in simple settings</li>
                        <li>Download On Device transcription model (Higher Quality or Faster Processing)</li>
                        <li>Download one or more AI summary models</li>
                        <li>Uses On Device transcription for transcription (requires model download)</li>
                        <li>Uses downloaded LLM models for AI summaries</li>
                    </ul>
                </p>
                <p><strong>Available Models</strong>:
                    <ul>
                        <li><strong>Recommended Models</strong> (by device RAM):
                            <ul>
                                <li><strong>8GB+ RAM</strong>: Granite 4.0 H Tiny (4.3 GB) - Recommended for best quality</li>
                                <li><strong>6GB+ RAM</strong>: Granite 4.0 Micro (2.1 GB) - Recommended for fast processing</li>
                                <li><strong>6GB+ RAM</strong>: Gemma 3n E2B (3.0 GB) - Good quality, smaller size</li>
                                <li><strong>8GB+ RAM</strong>: Gemma 3n E4B (4.5 GB) - Best overall quality</li>
                                <li><strong>6GB+ RAM</strong>: Ministral 3B (2.1 GB) - Best for tasks and reminders</li>
                            </ul>
                        </li>
                        <li><strong>Experimental Models</strong> (enable in settings):
                            <ul>
                                <li><strong>4GB+ RAM</strong>: LFM 2.5 1.2B (731 MB) - Fast, minimal summaries (summary only)</li>
                                <li><strong>4GB+ RAM</strong>: Qwen3 1.7B (1.1 GB) - Latest Qwen3 model (summary only)</li>
                                <li><strong>8GB+ RAM</strong>: Qwen3 4B (2.7 GB) - Excellent detail extraction</li>
                            </ul>
                        </li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Privacy-conscious users, offline use, recordings under 60 minutes</p>
                <p><strong>Limitations</strong>:
                    <ul>
                        <li>Best for recordings under 60 minutes</li>
                        <li>Requires 2-3GB storage per model</li>
                        <li>May be less accurate than cloud services</li>
                    </ul>
                </p>
            </div>

            <div class="engine-card">
                <h4>2. OpenAI Integration</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Pay-per-use (very affordable)<br>
                <strong>Privacy</strong>: Data sent to OpenAI<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Best for</strong>: High-quality results, advanced features</p>
            </div>

            <div class="engine-card">
                <h4>3. Google AI Studio</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-free">Free tier</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Free tier available, then pay-per-use<br>
                <strong>Privacy</strong>: Data sent to Google<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Available Models</strong>:
                    <ul>
                        <li><strong>Gemini 2.5 Flash</strong> (Default): Fast and efficient for most tasks</li>
                        <li><strong>Gemini 2.5 Flash Lite</strong>: Lightweight variant for quick processing</li>
                        <li><strong>Gemini 3 Pro Preview</strong>: Advanced reasoning and analysis (Preview)</li>
                        <li><strong>Gemini 3 Flash Preview</strong>: Fast next-generation model (Preview)</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Balanced performance and cost, with free tier for getting started</p>
            </div>

            <div class="engine-card">
                <h4>4. OpenAI API Compatible</h4>
                <span class="engine-type type-cloud">Cloud/Local</span>
                <span class="engine-type type-free">Flexible</span>
                <p><strong>Type</strong>: OpenAI-compatible API endpoint<br>
                <strong>Cost</strong>: Varies by provider<br>
                <strong>Privacy</strong>: Depends on provider<br>
                <strong>Internet</strong>: Required (unless local server)</p>
                <p><strong>Supported Providers</strong>: This single engine option works with multiple providers:
                    <ul>
                        <li><strong>LiteLLM</strong>: Open-source proxy for multiple providers</li>
                        <li><strong>llama.cpp</strong>: High-performance local LLM inference server</li>
                        <li><strong>Nebius</strong>: Cloud provider with OpenAI-compatible API</li>
                        <li><strong>Groq</strong>: Fast inference with OpenAI-compatible API</li>
                        <li><strong>Custom Servers</strong>: Any OpenAI-compatible endpoint</li>
                    </ul>
                </p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI API Compatible</li>
                        <li>Enter your API key (from your chosen provider, or use "no-key" for local servers)</li>
                        <li>Set base URL to your provider's endpoint:
                            <ul>
                                <li>Groq: <code>https://api.groq.com/v1</code></li>
                                <li>Nebius: Your Nebius endpoint URL</li>
                                <li>LiteLLM: Your LiteLLM server URL</li>
                                <li>llama.cpp: Your llama.cpp server URL (default: <code>http://localhost:8080</code>)</li>
                            </ul>
                        </li>
                        <li>Select model (use your provider's model name)</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Using LiteLLM, llama.cpp, Nebius, Groq, or other OpenAI-compatible services</p>
            </div>

            <div class="engine-card">
                <h4>5. Mistral AI</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI processing and transcription<br>
                <strong>Cost</strong>: Pay-per-use (summarization varies by model; transcription $0.003/min)<br>
                <strong>Privacy</strong>: Data sent to Mistral AI<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Summarization Models</strong>:
                    <ul>
                        <li><strong>Mistral Large (25.12)</strong>: Most capable model, 128K context window (Premium tier)</li>
                        <li><strong>Mistral Medium (25.08)</strong>: Balanced performance and cost, 128K context (Standard tier)</li>
                        <li><strong>Magistral Medium (25.09)</strong>: Economy option, 40K context window (Economy tier)</li>
                    </ul>
                </p>
                <p><strong>Transcription</strong>:
                    <ul>
                        <li><strong>Voxtral Mini Transcribe</strong>: Speech-to-text at $0.003/min with optional speaker diarization</li>
                        <li>Supports MP3, MP4, M4A, WAV, FLAC, OGG, WebM</li>
                        <li>Automatic language detection or explicit language code</li>
                    </ul>
                </p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí Mistral AI</li>
                        <li>Enter your Mistral API key</li>
                        <li>Select summarization model (Large, Medium, or Magistral)</li>
                        <li>For transcription: go to Settings ‚Üí Transcription Settings and select "Mistral AI"</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Fast, high-quality summaries and affordable cloud transcription with speaker diarization</p>
            </div>

            <div class="engine-card">
                <h4>6. AWS Bedrock</h4>
                <span class="engine-type type-cloud">Cloud-based</span>
                <span class="engine-type type-paid">Pay-per-use</span>
                <p><strong>Type</strong>: Cloud-based AI<br>
                <strong>Cost</strong>: Pay-per-use<br>
                <strong>Privacy</strong>: Data sent to AWS<br>
                <strong>Internet</strong>: Required</p>
                <p><strong>Best for</strong>: Enterprise features</p>
            </div>

            <div class="engine-card">
                <h4>7. Ollama</h4>
                <span class="engine-type type-local">Local AI</span>
                <span class="engine-type type-free">Free</span>
                <p><strong>Type</strong>: Local LLM server<br>
                <strong>Cost</strong>: Free (requires your own server)<br>
                <strong>Privacy</strong>: 100% local<br>
                <strong>Internet</strong>: Not required for processing</p>
                <p><strong>Setup</strong>:
                    <ul>
                        <li>Install Ollama server on your local machine or network</li>
                        <li>Go to Settings ‚Üí AI Settings ‚Üí Ollama</li>
                        <li>Set server URL (default: <code>http://localhost</code>)</li>
                        <li>Set port (default: 11434)</li>
                        <li>Select model (llama2:7b, qwen3:30b, etc.)</li>
                        <li>Test the connection</li>
                    </ul>
                </p>
                <p><strong>Best for</strong>: Privacy, customizable models, offline use</p>
            </div>

        </div>

        <h3>Setup Instructions for Each Engine</h3>

        <h4>OpenAI Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://platform.openai.com" target="_blank">platform.openai.com</a></li>
            <li><strong>Create Account</strong>: Sign up for an OpenAI account</li>
            <li><strong>Generate API Key</strong>: Go to API Keys section and create a new key</li>
            <li><strong>Configure in App</strong>: 
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI</li>
                    <li>Enter your API key</li>
                    <li>Select your preferred model</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>Available OpenAI Models</h4>
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Type</th>
                    <th>Best For</th>
                    <th>Tier</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>GPT-4.1</strong></td>
                    <td>Summarization</td>
                    <td>Most robust and comprehensive analysis with advanced reasoning capabilities</td>
                    <td>Premium</td>
                </tr>
                <tr>
                    <td><strong>GPT-4.1 Mini</strong></td>
                    <td>Summarization</td>
                    <td>Balanced performance and cost, suitable for most summarization tasks (Default)</td>
                    <td>Standard</td>
                </tr>
                <tr>
                    <td><strong>GPT-4.1 Nano</strong></td>
                    <td>Summarization</td>
                    <td>Fastest and most economical for basic summarization needs</td>
                    <td>Economy</td>
                </tr>
                <tr>
                    <td><strong>GPT-5 Mini</strong></td>
                    <td>Summarization</td>
                    <td>Next-generation model with enhanced reasoning and efficiency</td>
                    <td>Premium</td>
                </tr>
            </tbody>
        </table>
        
        <h4>OpenAI Transcription Models</h4>
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Type</th>
                    <th>Best For</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>GPT-4o Transcribe</strong></td>
                    <td>Transcription</td>
                    <td>Most robust transcription with GPT-4o model. Supports streaming.</td>
                </tr>
                <tr>
                    <td><strong>GPT-4o Mini Transcribe</strong></td>
                    <td>Transcription</td>
                    <td>Cheapest and fastest transcription with GPT-4o Mini model. Supports streaming. Recommended for most use cases.</td>
                </tr>
                <tr>
                    <td><strong>Whisper-1</strong></td>
                    <td>Transcription</td>
                    <td>Legacy transcription with Whisper V2 model. Does not support streaming.</td>
                </tr>
            </tbody>
        </table>

        <h4>Google AI Studio Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://aistudio.google.com" target="_blank">aistudio.google.com</a></li>
            <li><strong>Create Account</strong>: Sign up for Google AI Studio</li>
            <li><strong>Generate API Key</strong>: Create a new API key</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Google AI Studio</li>
                    <li>Enter your API key</li>
                    <li>Select model:
                        <ul>
                            <li><strong>Gemini 2.5 Flash</strong> (Default): Fast and efficient for most tasks</li>
                            <li><strong>Gemini 2.5 Flash Lite</strong>: Lightweight variant for quick processing</li>
                            <li><strong>Gemini 3 Pro Preview</strong>: Advanced reasoning and analysis (Preview)</li>
                            <li><strong>Gemini 3 Flash Preview</strong>: Fast next-generation model (Preview)</li>
                        </ul>
                    </li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>OpenAI API Compatible Integration</h4>
        <div class="info-box">
            <h4>üìå Important Note</h4>
            <p><strong>OpenAI API Compatible is a single engine option</strong> that works with multiple providers. You don't select Nebius, Groq, LiteLLM, or vLLM as separate engines - instead, you configure the "OpenAI API Compatible" option with your chosen provider's settings.</p>
        </div>
        <ol class="step-list">
            <li><strong>Choose Your Provider</strong>: Select one of these OpenAI-compatible services:
                <ul>
                    <li><strong>LiteLLM</strong>: Open-source proxy for multiple providers
                        <ul>
                            <li>Base URL: Your LiteLLM server URL (e.g., <code>http://localhost:4000/v1</code>)</li>
                            <li>Get API key from your LiteLLM configuration</li>
                            <li>Documentation: <a href="https://github.com/BerriAI/litellm" target="_blank">github.com/BerriAI/litellm</a></li>
                        </ul>
                    </li>
                    <li><strong>llama.cpp</strong>: High-performance local LLM inference server
                        <ul>
                            <li>Base URL: Your llama.cpp server URL (default: <code>http://localhost:8080</code>)</li>
                            <li>API key: Use "no-key" or leave empty for local servers</li>
                            <li>Installation: Clone from <a href="https://github.com/ggerganov/llama.cpp" target="_blank">github.com/ggerganov/llama.cpp</a>, build with <code>make</code>, then run <code>./server --model &lt;model_file&gt;</code></li>
                            <li>Documentation: See <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp README</a> for full setup instructions</li>
                            <li>Alternative: Use <code>llama-cpp-python</code> with <code>pip install 'llama-cpp-python[server]'</code> and run <code>python3 -m llama_cpp.server --model /path/to/model.gguf</code></li>
                        </ul>
                    </li>
                    <li><strong>Nebius</strong>: Cloud provider with OpenAI-compatible API
                        <ul>
                            <li>Base URL: Your Nebius endpoint URL</li>
                            <li>Get API key from Nebius console</li>
                        </ul>
                    </li>
                    <li><strong>Groq</strong>: Fast inference with OpenAI-compatible API
                        <ul>
                            <li>Base URL: <code>https://api.groq.com/v1</code></li>
                            <li>Get API key from <a href="https://console.groq.com" target="_blank">console.groq.com</a></li>
                        </ul>
                    </li>
                    <li><strong>Custom Server</strong>: Your own OpenAI-compatible endpoint
                        <ul>
                            <li>Base URL: Your server's endpoint URL</li>
                            <li>API key: As configured on your server</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Get API Key</strong>: Obtain an API key from your chosen provider (if required)</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí OpenAI API Compatible</li>
                    <li>Enter your API key (from your chosen provider)</li>
                    <li>Set base URL to your provider's endpoint (see examples above)</li>
                    <li>Select model (use your provider's exact model name, e.g., <code>llama-3.1-70b-versatile</code> for Groq)</li>
                    <li>Configure temperature and max tokens</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° OpenAI Compatible Tips</h4>
            <ul>
                <li><strong>Single Engine Option</strong>: All providers (Nebius, Groq, LiteLLM, llama.cpp) use the same "OpenAI API Compatible" engine option - just change the base URL and API key</li>
                <li><strong>Base URL Examples</strong>:
                    <ul>
                        <li>Groq: <code>https://api.groq.com/v1</code></li>
                        <li>Local llama.cpp: <code>http://localhost:8080</code> (default port)</li>
                        <li>Local LiteLLM: <code>http://localhost:4000/v1</code></li>
                        <li>Nebius: Your Nebius endpoint URL</li>
                    </ul>
                </li>
                <li><strong>Model Names</strong>: Use the exact model name your provider supports (e.g., Groq uses names like <code>llama-3.1-70b-versatile</code>, not <code>gpt-4o</code>)</li>
                <li><strong>Local Servers</strong>: For local servers (llama.cpp, LiteLLM), ensure your device can reach the server IP address</li>
                <li><strong>llama.cpp Setup</strong>: 
                    <ul>
                        <li>Native server: Clone <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp</a>, build with <code>make</code>, run <code>./server --model &lt;model.gguf&gt;</code></li>
                        <li>Python server: Install with <code>pip install 'llama-cpp-python[server]'</code>, run <code>python3 -m llama_cpp.server --model /path/to/model.gguf</code></li>
                        <li>Default port is 8080, API key can be "no-key" or empty</li>
                    </ul>
                </li>
                <li><strong>Transcription</strong>: OpenAI API Compatible is also available for transcription in Settings ‚Üí Transcription Settings</li>
            </ul>
        </div>

        <h4>Mistral AI Integration</h4>
        <ol class="step-list">
            <li><strong>Get API Key</strong>: Visit <a href="https://console.mistral.ai" target="_blank">console.mistral.ai</a></li>
            <li><strong>Create Account</strong>: Sign up for a Mistral AI account</li>
            <li><strong>Generate API Key</strong>: Create a new API key in your account settings</li>
            <li><strong>Configure Summarization</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Mistral AI</li>
                    <li>Enter your API key</li>
                    <li>Select summarization model:
                        <ul>
                            <li><strong>Mistral Large (25.12)</strong>: Most capable, 128K context (Premium)</li>
                            <li><strong>Mistral Medium (25.08)</strong>: Balanced performance, 128K context (Standard)</li>
                            <li><strong>Magistral Medium (25.09)</strong>: Economy option, 40K context</li>
                        </ul>
                    </li>
                    <li>Configure temperature and other parameters</li>
                    <li>Test the connection</li>
                </ul>
            </li>
            <li><strong>Configure Transcription (Optional)</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings</li>
                    <li>Select "Mistral AI" as your transcription engine</li>
                    <li>Tap "Configure" to open Mistral transcription settings</li>
                    <li>The same API key is shared between summarization and transcription</li>
                    <li>Enable speaker diarization if you want speaker labels</li>
                    <li>Optionally set a language code for better accuracy</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Mistral Transcription Tips</h4>
            <ul>
                <li><strong>Cost</strong>: Voxtral Mini transcription costs $0.003 per minute of audio</li>
                <li><strong>Diarization</strong>: When enabled, the transcription identifies and labels different speakers</li>
                <li><strong>Language</strong>: Leave empty for auto-detection, or specify a code (e.g., "en", "fr", "es") for better accuracy</li>
                <li><strong>Supported Formats</strong>: MP3, MP4, M4A, WAV, FLAC, OGG, WebM</li>
                <li><strong>Large Files</strong>: Files over 24MB are automatically chunked for processing</li>
            </ul>
        </div>

        <h4>Ollama Integration</h4>
        <ol class="step-list">
            <li><strong>Install Ollama</strong>: Visit <a href="https://ollama.com" target="_blank">ollama.com</a> and install Ollama on your local machine or server</li>
            <li><strong>Download Recommended Models</strong>:
                <pre><code>ollama pull qwen3:30b
ollama pull gpt-oss:20b
ollama pull mistral-small3.2</code></pre>
            </li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí Ollama</li>
                    <li>Set server URL (default: <code>http://localhost</code> for local, or your server's IP address)</li>
                    <li>Set port (default: 11434)</li>
                    <li><strong>Run a Model Scan</strong>: Tap the refresh button to scan your Ollama server for available models</li>
                    <li>Select your preferred model:
                        <ul>
                            <li><strong>Recommended</strong>: qwen3:30b, gpt-oss:20b, mistral-small3.2</li>
                            <li>Available models will be fetched from your Ollama server</li>
                        </ul>
                    </li>
                    <li>Configure temperature and max tokens</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Ollama Tips</h4>
            <ul>
                <li><strong>Local Server</strong>: Use <code>http://localhost:11434</code> if Ollama is running on the same device</li>
                <li><strong>Network Server</strong>: Use your server's IP address (e.g., <code>http://192.168.1.100:11434</code>)</li>
                <li><strong>Model Scan</strong>: Always run a model scan after connecting to fetch the list of models installed on your Ollama server</li>
                <li><strong>Performance</strong>: Larger models provide better results but require more RAM and processing time</li>
            </ul>
        </div>

        <h4>AWS Bedrock Integration</h4>
        <ol class="step-list">
            <li><strong>AWS Account</strong>: Create an AWS account</li>
            <li><strong>Enable Bedrock</strong>: Enable AWS Bedrock service</li>
            <li><strong>Create IAM User</strong>: Create user with Bedrock permissions</li>
            <li><strong>Get Credentials</strong>: Generate access keys</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí AI Settings ‚Üí AWS Bedrock</li>
                    <li>Enter AWS credentials</li>
                    <li>Select region</li>
                    <li>Choose foundation model:
                        <ul>
                            <li><strong>Claude 4.5 Haiku</strong> (Default): Fast and efficient model optimized for quick responses (Standard tier)</li>
                            <li><strong>Claude Sonnet 4.5</strong>: Latest Claude Sonnet with advanced reasoning, coding, and analysis capabilities (Premium tier)</li>
                            <li><strong>Llama 4 Maverick 17B Instruct</strong>: Meta's latest Llama 4 model with enhanced reasoning and performance (Economy tier)</li>
                        </ul>
                    </li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>

        <h4>Whisper Integration (Local Server)</h4>
        <ol class="step-list">
            <li><strong>Install Whisper Server</strong>: 
                <pre><code># Using Docker (recommended)
docker run -d -p 9000:9000 \
  -e ASR_MODEL=base \
  -e ASR_ENGINE=openai_whisper \
  onerahmet/openai-whisper-asr-webservice:latest</code></pre>
            </li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings ‚Üí Whisper (Local Server)</li>
                    <li>Set server URL (e.g., <code>http://localhost</code> or <code>http://192.168.1.100</code>)</li>
                    <li>Set port (default: 9000)</li>
                    <li>Select protocol (REST API or Wyoming)</li>
                    <li>Select model size (tiny, base, small, medium, large-v3)</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° Whisper Protocol Options</h4>
            <ul>
                <li><strong>REST API</strong>: Traditional HTTP REST API with file uploads</li>
                <li><strong>Wyoming</strong>: Modern streaming protocol with WebSocket connection</li>
            </ul>
        </div>

        <h4>AWS Transcribe Integration</h4>
        <ol class="step-list">
            <li><strong>AWS Account</strong>: Create an AWS account</li>
            <li><strong>Enable Transcribe</strong>: Enable AWS Transcribe service in your AWS console</li>
            <li><strong>Create IAM User</strong>: Create user with Transcribe permissions</li>
            <li><strong>Get Credentials</strong>: Generate access keys</li>
            <li><strong>Configure in App</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings ‚Üí AWS Transcribe</li>
                    <li>Enter AWS access key ID</li>
                    <li>Enter AWS secret access key</li>
                    <li>Select region (e.g., us-east-1, eu-west-1)</li>
                    <li>Choose language</li>
                    <li>Test the connection</li>
                </ul>
            </li>
        </ol>
        <div class="info-box">
            <h4>üí° AWS Transcribe Tips</h4>
            <ul>
                <li><strong>IAM Permissions</strong>: Ensure your IAM user has <code>transcribe:StartTranscriptionJob</code> and <code>transcribe:GetTranscriptionJob</code> permissions</li>
                <li><strong>Regions</strong>: Choose a region close to you for better performance</li>
                <li><strong>Cost</strong>: AWS Transcribe charges per minute of audio transcribed</li>
            </ul>
        </div>

        <h4>On-Device AI Setup</h4>
        <ol class="step-list">
            <li><strong>Select On-Device AI</strong>: Choose "On-Device AI" in the simple settings page</li>
            <li><strong>Download Transcription Model</strong>: 
                <ul>
                    <li>You'll be prompted to configure On Device transcription</li>
                    <li>Go to Settings ‚Üí Transcription Settings ‚Üí On Device</li>
                    <li>Download either "Higher Quality" (~520MB) or "Faster Processing" (~150MB) model</li>
                    <li>See <a href="#on-device-transcription-setup">On Device Transcription Setup</a> section above for detailed model selection guide</li>
                </ul>
            </li>
            <li><strong>Download AI Summary Models</strong>: After saving, you'll be taken to the On-Device AI settings page:
                <ul>
                    <li>Select one or more AI summary models to download</li>
                    <li>Available models:
                        <ul>
                            <li><strong>Recommended Models</strong> (by device RAM):
                                <ul>
                                    <li><strong>8GB+ RAM</strong>: Granite 4.0 H Tiny (4.3 GB) - Recommended for best quality</li>
                                    <li><strong>6GB+ RAM</strong>: Granite 4.0 Micro (2.1 GB) - Recommended for fast processing</li>
                                    <li><strong>6GB+ RAM</strong>: Gemma 3n E2B (3.0 GB) - Good quality, smaller size</li>
                                    <li><strong>8GB+ RAM</strong>: Gemma 3n E4B (4.5 GB) - Best overall quality</li>
                                    <li><strong>6GB+ RAM</strong>: Ministral 3B (2.1 GB) - Best for tasks and reminders</li>
                                </ul>
                            </li>
                            <li><strong>Experimental Models</strong> (enable in settings):
                                <ul>
                                    <li><strong>4GB+ RAM</strong>: LFM 2.5 1.2B (731 MB) - Fast, minimal summaries (summary only)</li>
                                    <li><strong>4GB+ RAM</strong>: Qwen3 1.7B (1.1 GB) - Latest Qwen3 model (summary only)</li>
                                    <li><strong>8GB+ RAM</strong>: Qwen3 4B (2.7 GB) - Excellent detail extraction</li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                    <li>Download progress is shown with speed and time remaining</li>
                </ul>
            </li>
            <li><strong>Model Selection</strong>: Choose which model to use for summaries</li>
            <li><strong>Configuration</strong>: Adjust generation settings (temperature, max tokens, etc.)</li>
            <li><strong>Transcription</strong>: Uses On Device transcription (requires model download as described above)</li>
        </ol>
        <div class="info-box">
            <h4>üíæ Storage Requirements</h4>
            <p>On-Device AI requires 2-3GB of storage per AI summary model, plus 150-520MB for the On Device transcription model. Make sure you have sufficient free space before downloading models.</p>
            <h4>üì± Device Requirements</h4>
            <ul>
                <li><strong>Transcription</strong>: iOS 17.0+, 4GB+ RAM (most modern iPhones and iPads)</li>
                <li><strong>AI Summary</strong>: iPhone 15 Pro, iPhone 16 or newer, iOS 18.1+ (requires more processing power)</li>
            </ul>
        </div>

        <h2 id="transcription-configuration">üìù Transcription Configuration</h2>
        
        <div class="info-box">
            <h3>üîí On Device Transcription</h3>
            <p>For complete privacy, use On Device transcription. Your audio is processed entirely on your device and never leaves your iPhone or iPad. See the <a href="#on-device-transcription-setup">On Device Transcription Setup</a> section below for complete setup instructions.</p>
        </div>

        <h3>Engine Selection</h3>
        <ol class="step-list">
            <li>Go to Settings ‚Üí Transcription Settings</li>
            <li>Select your preferred transcription engine</li>
            <li>Configure the selected engine (if required)</li>
            <li>Test the connection</li>
        </ol>

        <h3>Available Transcription Engines</h3>
        <ul>
            <li><strong>On Device</strong>: High-quality on-device transcription. Your audio never leaves your device, ensuring complete privacy. Requires model download (~150-520MB). Best for privacy-conscious users.</li>
            <li><strong>OpenAI</strong>: Cloud-based transcription using OpenAI's GPT-4o models and Whisper API. Supports multiple models:
                <ul>
                    <li><strong>GPT-4o Transcribe</strong>: Most robust transcription with GPT-4o model. Supports streaming for real-time transcription.</li>
                    <li><strong>GPT-4o Mini Transcribe</strong>: Cheapest and fastest transcription with GPT-4o Mini model. Supports streaming. Recommended for most use cases.</li>
                    <li><strong>Whisper-1</strong>: Legacy transcription with Whisper V2 model. Does not support streaming.</li>
                </ul>
            </li>
            <li><strong>Mistral AI</strong>: Cloud-based transcription using Mistral's Voxtral Mini model ($0.003/min). Features:
                <ul>
                    <li><strong>Speaker Diarization</strong>: Optional ‚Äî identifies and labels different speakers in the audio</li>
                    <li><strong>Language Support</strong>: Automatic detection or explicit language code for better accuracy</li>
                    <li><strong>Supported Formats</strong>: MP3, MP4, M4A, WAV, FLAC, OGG, WebM</li>
                    <li><strong>Large Files</strong>: Automatic chunking for files over 24MB</li>
                </ul>
            </li>
            <li><strong>Whisper (Local Server)</strong>: High-quality transcription using OpenAI's Whisper model on your local server (REST API or Wyoming protocol)</li>
            <li><strong>AWS Transcribe</strong>: Cloud-based transcription service with support for long audio files</li>
        </ul>

        <h3 id="on-device-transcription-setup">On Device Transcription Setup</h3>
        <div class="info-box">
            <h4>üîí Privacy-First Transcription</h4>
            <p>On Device transcription processes your audio entirely on your device. Your audio files never leave your iPhone or iPad, ensuring complete privacy and security.</p>
        </div>
        
        <h4>Initial Setup</h4>
        <ol class="step-list">
            <li><strong>Enable On Device</strong>:
                <ul>
                    <li>Go to Settings ‚Üí Transcription Settings</li>
                    <li>Select "On Device" as your transcription engine</li>
                    <li>Tap "Configure" to open On Device settings</li>
                </ul>
            </li>
            <li><strong>Download a Model</strong>:
                <ul>
                    <li>In On Device settings, you'll see two model options:
                        <ul>
                            <li><strong>Higher Quality</strong> (~520MB): Best accuracy and quality. Takes longer to process but produces more accurate transcriptions.</li>
                            <li><strong>Faster Processing</strong> (~150MB): Faster transcription with good quality. Ideal for quick transcriptions with slightly lower accuracy.</li>
                        </ul>
                    </li>
                    <li>Tap the download button next to your preferred model</li>
                    <li>Wait for download to complete (progress is shown with speed and time remaining)</li>
                    <li>Model download requires internet connection, but transcription works offline after download</li>
                </ul>
            </li>
            <li><strong>Device Requirements</strong>:
                <ul>
                    <li><strong>RAM</strong>: Requires 4GB+ RAM (most modern iPhones and iPads)</li>
                    <li><strong>iOS</strong>: iOS 17.0 or later</li>
                    <li><strong>Storage</strong>: 150-520MB free space depending on model selected</li>
                </ul>
            </li>
            <li><strong>Test the Model</strong>:
                <ul>
                    <li>Once downloaded, tap "Test Model Loading" to verify it works</li>
                    <li>First load may take 30-60 seconds as the model compiles</li>
                    <li>If you see errors, try deleting and re-downloading the model</li>
                </ul>
            </li>
        </ol>

        <h4>Model Selection Guide</h4>
        <div class="info-box">
            <h4>üìã Which Model Should I Use?</h4>
            <table>
                <thead>
                    <tr>
                        <th>Use Case</th>
                        <th>Recommended Model</th>
                        <th>Why?</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Voice Notes / Journaling</strong></td>
                        <td>Faster Processing</td>
                        <td>You are close to the mic; audio is clear. Speed is better.</td>
                    </tr>
                    <tr>
                        <td><strong>Meeting / Interview</strong></td>
                        <td>Higher Quality</td>
                        <td>Handling multiple voices and distance from the mic requires the extra accuracy.</td>
                    </tr>
                    <tr>
                        <td><strong>Noisy Environment</strong></td>
                        <td>Higher Quality</td>
                        <td>Faster Processing will fail to separate voice from noise.</td>
                    </tr>
                    <tr>
                        <td><strong>Long Battery Life Needed</strong></td>
                        <td>Faster Processing</td>
                        <td>Higher Quality uses significantly more power per second of audio.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h4>Using On Device Transcription</h4>
        <ol class="step-list">
            <li><strong>Record Audio</strong>: Create a recording as usual</li>
            <li><strong>Generate Transcript</strong>: 
                <ul>
                    <li>Open your recording</li>
                    <li>Tap "Generate Transcript"</li>
                    <li>On Device transcription will process your audio locally</li>
                </ul>
            </li>
            <li><strong>Processing Time</strong>:
                <ul>
                    <li><strong>Faster Processing</strong>: Approximately 3x faster than Higher Quality</li>
                    <li><strong>Higher Quality</strong>: Takes longer but produces more accurate results</li>
                    <li>Processing time depends on audio length and device performance</li>
                </ul>
            </li>
            <li><strong>View Results</strong>: Once complete, your transcript appears with full text and timestamps</li>
        </ol>

        <div class="success-box">
            <h4>‚úÖ Benefits of On Device Transcription</h4>
            <ul>
                <li><strong>Complete Privacy</strong>: Your audio never leaves your device</li>
                <li><strong>Works Offline</strong>: No internet required after model download</li>
                <li><strong>No API Costs</strong>: Free to use after initial model download</li>
                <li><strong>Fast Processing</strong>: Especially with "Faster Processing" model</li>
                <li><strong>High Quality</strong>: Excellent accuracy with "Higher Quality" model</li>
            </ul>
        </div>

        <div class="warning-box">
            <h4>‚ö†Ô∏è Important Notes</h4>
            <ul>
                <li><strong>Model Download</strong>: Requires internet connection and sufficient storage space</li>
                <li><strong>First Load</strong>: First transcription after download may take 30-60 seconds as the model compiles</li>
                <li><strong>Device Compatibility</strong>: Some older devices may not support On Device transcription</li>
                <li><strong>Battery Usage</strong>: Higher Quality model uses more battery than Faster Processing</li>
                <li><strong>Storage</strong>: Models take 150-520MB of storage space</li>
            </ul>
        </div>

        <h3>Large File Processing</h3>
        <ul>
            <li><strong>Automatic Chunking</strong>: Files over 5 minutes are automatically split</li>
            <li><strong>Progress Tracking</strong>: Real-time progress updates</li>
            <li><strong>Background Processing</strong>: Continues when app is minimized</li>
            <li><strong>Timeout Settings</strong>: Configurable processing time limits</li>
        </ul>

        <h2 id="working-with-summaries">üìä Working with Summaries</h2>

        <h3>Viewing Summaries</h3>
        <ol class="step-list">
            <li>Tap the "Summaries" tab</li>
            <li>Browse your recordings with AI-generated summaries</li>
            <li>Tap any summary to view details</li>
        </ol>

        <h3>Summary Features</h3>
        <ul>
            <li><strong>Expandable Sections</strong>: Tap to expand/collapse sections</li>
            <li><strong>Task Extraction</strong>: AI-identified actionable items</li>
            <li><strong>Reminder Detection</strong>: Time-sensitive reminders</li>
            <li><strong>Priority Indicators</strong>: Color-coded task priorities</li>
            <li><strong>Location Maps</strong>: Interactive maps showing recording location</li>
        </ul>

        <h3 id="search-and-filtering">Search and Filtering</h3>
        <p>BisonNotes AI includes powerful search and filtering capabilities to help you find your recordings, transcripts, and summaries quickly.</p>
        
        <h4>Search Functionality</h4>
        <p>Search is available in three main views:</p>
        <ul>
            <li><strong>Summaries View</strong>: Search across summary content, tasks, reminders, titles, and recording names</li>
            <li><strong>Transcripts View</strong>: Search through transcript text and recording names</li>
            <li><strong>Recordings View</strong>: Search by recording name</li>
        </ul>
        <p><strong>How to use:</strong></p>
        <ol class="step-list">
            <li>Tap the search bar at the top of any view</li>
            <li>Type your search terms</li>
            <li>Results filter in real-time as you type</li>
            <li>Search is case-insensitive and matches partial text</li>
        </ol>

        <h4>Date Filters</h4>
        <p>Date range filtering helps you find content from specific time periods:</p>
        <ul>
            <li><strong>Available in</strong>: Summaries, Transcripts, and Recordings views</li>
            <li><strong>How to use</strong>:
                <ol class="step-list">
                    <li>Tap the filter icon (three horizontal lines with circle) in the navigation bar</li>
                    <li>Select a start date and end date</li>
                    <li>Tap "Apply" to filter results</li>
                    <li>The active filter is shown with a banner at the top of the list</li>
                    <li>Tap the X on the banner to clear the filter</li>
                </ol>
            </li>
        </ul>
        <div class="info-box">
            <h4>üí° Filter Behavior</h4>
            <ul>
                <li>Filters can be combined with search for precise results</li>
                <li>Date range includes the full day (00:00:00 to 23:59:59) for both start and end dates</li>
                <li>Filters persist until manually cleared</li>
            </ul>
        </div>

        <h3>Editing Recording Metadata</h3>

        <h4>Changing Recording Title</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>Scroll to "Titles" section</li>
            <li>Tap "Edit" next to any title</li>
            <li>Enter new title or select from AI-generated alternatives</li>
            <li>Tap "Use This Title"</li>
        </ol>

        <h4>Setting Custom Date & Time</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>Scroll to "Recording Date & Time" section</li>
            <li>Tap "Set Custom Date & Time"</li>
            <li>Use date and time pickers</li>
            <li>Tap "Save"</li>
        </ol>

        <h4>Adding/Editing Location</h4>
        <ol class="step-list">
            <li>Open a summary</li>
            <li>In the location section, tap "Add Location" or "Edit Location"</li>
            <li>Choose from:
                <ul>
                    <li><strong>Current Location</strong>: Use device GPS</li>
                    <li><strong>Map Selection</strong>: Pick location on map</li>
                    <li><strong>Manual Entry</strong>: Enter coordinates manually</li>
                </ul>
            </li>
            <li>Tap "Save"</li>
        </ol>

        <h2 id="audio-playback">üéµ Audio Playback</h2>

        <h3>Basic Playback</h3>
        <ol class="step-list">
            <li>Go to "Recordings" tab</li>
            <li>Tap any recording to play</li>
            <li>Use playback controls:
                <ul>
                    <li><strong>Play/Pause</strong>: Center button</li>
                    <li><strong>Skip 15s</strong>: Side buttons</li>
                    <li><strong>Scrub</strong>: Drag progress bar</li>
                </ul>
            </li>
        </ol>

        <h3>Advanced Playback</h3>
        <ul>
            <li><strong>Seek Control</strong>: Drag the scrubber for precise positioning</li>
            <li><strong>Background Playback</strong>: Audio continues when app is minimized</li>
            <li><strong>Audio Session Management</strong>: Handles interruptions gracefully</li>
        </ul>

        <h2 id="settings-configuration">‚öôÔ∏è Settings & Configuration</h2>

        <h3 id="simple-vs-advanced-settings">Simple Settings vs Advanced Settings</h3>
        <div class="info-box">
            <h4>üéØ Understanding the Two Settings Interfaces</h4>
            <p>BisonNotes AI has two settings interfaces designed for different use cases:</p>
        </div>
        
        <h4>Simple Settings Page</h4>
        <p>The simple settings page appears on first launch and provides quick setup for the most common configurations:</p>
        <ul>
            <li><strong>Automatic Detection</strong>: The page automatically detects your current configuration:
                <ul>
                    <li>If both AI engine and transcription are set to "OpenAI" ‚Üí Shows "OpenAI" option</li>
                    <li>If AI engine is "On-Device AI" and transcription is "On Device" ‚Üí Shows "On-Device AI" option</li>
                    <li>Any other configuration ‚Üí Automatically shows "Advanced & Other Options"</li>
                </ul>
            </li>
            <li><strong>Preserves Settings</strong>: If you manually switch to "Advanced & Other Options", your current settings are preserved (not reset to blank)</li>
            <li><strong>Quick Access</strong>: Tap "Advanced Options" button to access full settings at any time</li>
            <li><strong>Immediate Action</strong>: 
                <ul>
                    <li>Selecting "OpenAI" ‚Üí Enter API key and save</li>
                    <li>Selecting "On-Device AI" ‚Üí Saves and immediately opens On-Device AI settings to download models</li>
                    <li>Selecting "Advanced & Other Options" ‚Üí Saves and immediately opens advanced settings page</li>
                </ul>
            </li>
        </ul>

        <h4>Advanced Settings Page</h4>
        <p>The advanced settings page provides full control over all configuration options:</p>
        <ul>
                    <li><strong>AI Processing</strong>: Configure AI summarization engines
                <ul>
                    <li>On-Device AI</li>
                    <li>OpenAI</li>
                    <li>Google AI Studio</li>
                    <li>AWS Bedrock</li>
                    <li>Mistral AI</li>
                    <li>OpenAI API Compatible</li>
                    <li>Ollama</li>
                </ul>
            </li>
            <li><strong>Transcription Engine</strong>: Configure transcription engines
                <ul>
                    <li>On Device</li>
                    <li>OpenAI</li>
                    <li>Whisper (Local Server)</li>
                    <li>AWS Transcribe</li>
                    <li>OpenAI API Compatible</li>
                </ul>
            </li>
            <li><strong>Microphone Selection</strong>: Choose from available microphones (appears below AI and Transcription sections)</li>
            <li><strong>Preferences</strong>: Display preferences, time format, etc.</li>
            <li><strong>Advanced Settings</strong>: Location services, iCloud sync, background processing</li>
        </ul>

        <div class="info-box">
            <h4>üîÑ Switching Between Simple and Advanced</h4>
            <ul>
                <li><strong>From Simple to Advanced</strong>: Tap "Advanced Options" button in the top right</li>
                <li><strong>From Advanced to Simple</strong>: The simple settings page automatically detects your configuration when you return to it</li>
                <li><strong>Automatic Updates</strong>: If you change settings in advanced options, the simple settings page will automatically switch to "Advanced & Other Options" when you return</li>
            </ul>
        </div>

        <h3>Audio Settings</h3>
        <ul>
            <li><strong>Quality</strong>: Whisper Optimized (22 kHz, 64 kbps AAC) - Optimized for voice transcription</li>
            <li><strong>Microphone Selection</strong>: 
                <ul>
                    <li>Choose from available microphones (built-in, Bluetooth, USB devices)</li>
                    <li>Your selection is saved and used for all recordings</li>
                    <li>If selected microphone becomes unavailable, automatically falls back to iOS default</li>
                    <li>During recording, if microphone disconnects, recording continues with default microphone</li>
                </ul>
            </li>
            <li><strong>Mixed Audio</strong>: Record without interrupting system audio</li>
            <li><strong>Background Recording</strong>: Continue recording when app is minimized</li>
        </ul>

        <h3>AI Settings</h3>
        <ul>
            <li><strong>Engine Selection</strong>: Choose your preferred AI engine for summaries:
                <ul>
                    <li><strong>On-Device AI</strong>: Privacy-focused local AI processing</li>
                    <li><strong>OpenAI</strong>: Cloud-based AI with GPT models</li>
                    <li><strong>Google AI Studio</strong>: Gemini AI processing</li>
                    <li><strong>AWS Bedrock</strong>: Enterprise-grade Claude AI</li>
                    <li><strong>Mistral AI</strong>: Advanced AI processing with Mistral models</li>
                    <li><strong>OpenAI API Compatible</strong>: Connect to OpenAI-compatible endpoints (LiteLLM, llama.cpp, Nebius, Groq, etc.)</li>
                    <li><strong>Ollama</strong>: Local LLM server for privacy-focused processing</li>
                </ul>
            </li>
            <li><strong>Model Configuration</strong>: Adjust settings for selected engine (temperature, max tokens, etc.)</li>
            <li><strong>Connection Testing</strong>: Verify API connectivity</li>
            <li><strong>Batch Regeneration</strong>: Update all summaries with new engine</li>
        </ul>

        <h3>Background Processing</h3>
        <ul>
            <li><strong>Job Management</strong>: View active and completed jobs</li>
            <li><strong>Progress Tracking</strong>: Monitor long-running operations</li>
            <li><strong>Error Recovery</strong>: Automatic retry and error handling</li>
            <li><strong>Performance Monitoring</strong>: Real-time metrics</li>
        </ul>

        <h3>Data Management</h3>
        <ul>
            <li><strong>Migration Tools</strong>: Import legacy data</li>
            <li><strong>Database Maintenance</strong>: Clear and repair data</li>
            <li><strong>File Relationships</strong>: Manage audio, transcript, and summary files</li>
            <li><strong>Debug Tools</strong>: Advanced troubleshooting options</li>
        </ul>

        <h2 id="troubleshooting">üîß Troubleshooting</h2>

        <h3>Common Issues</h3>

        <h4>Recording Problems</h4>
        <ul>
            <li><strong>No Audio</strong>: Check microphone permissions</li>
            <li><strong>Poor Quality</strong>: Adjust audio quality settings</li>
            <li><strong>Background Recording</strong>: Enable in settings</li>
        </ul>

        <h4>AI Engine Issues</h4>
        <ul>
            <li><strong>Connection Failed</strong>: Check internet and API keys</li>
            <li><strong>Timeout Errors</strong>: Increase timeout settings</li>
            <li><strong>Authentication Errors</strong>: Verify API credentials</li>
        </ul>

        <h4>Transcription Problems</h4>
        <ul>
            <li><strong>No Transcription</strong>: Check engine configuration</li>
            <li><strong>Poor Quality</strong>: Try different engine or model</li>
            <li><strong>Large File Issues</strong>: Enable chunking for files over 5 minutes</li>
        </ul>

        <h4>Data Issues</h4>
        <ul>
            <li><strong>Missing Recordings</strong>: Use Data Migration tools</li>
            <li><strong>Corrupted Data</strong>: Clear and re-import data</li>
            <li><strong>Sync Problems</strong>: Check iCloud settings</li>
        </ul>

        <h3>Performance Optimization</h3>
        <ul>
            <li><strong>Battery Life</strong>: Use local engines for offline processing</li>
            <li><strong>Memory Usage</strong>: Close other apps during large file processing</li>
            <li><strong>Storage</strong>: Regularly clean up old recordings</li>
            <li><strong>Network</strong>: Use local engines to reduce data usage</li>
        </ul>

        <h2 id="advanced-features">üì± Advanced Features</h2>

        <h3>Background Processing</h3>
        <ul>
            <li><strong>Job Queue</strong>: Multiple operations run in background</li>
            <li><strong>Progress Tracking</strong>: Real-time updates for long operations</li>
            <li><strong>Error Recovery</strong>: Automatic retry for failed operations</li>
            <li><strong>Stale Job Cleanup</strong>: Automatic cleanup of abandoned jobs</li>
        </ul>

        <h3>File Management</h3>
        <ul>
            <li><strong>Import/Export</strong>: Support for various audio formats (M4A, MP3, WAV, CAF, AIFF, AIF)</li>
            <li><strong>Share Extension</strong>: Import audio directly from Voice Memos, Files, and other apps via the iOS share sheet (see <a href="#share-extension">Share Extension</a> section)</li>
            <li><strong>Combining Recordings</strong>: Merge two recordings into one continuous file (see <a href="#combining-recordings">Combining Recordings</a> section)</li>
            <li><strong>PDF Export</strong>: Professional PDF reports with three-pane header (metadata, local map, regional map), page numbers, and dedicated tasks/reminders sections</li>
            <li><strong>File Relationships</strong>: Maintains connections between audio, transcripts, and summaries</li>
            <li><strong>Orphaned File Detection</strong>: Identifies and manages disconnected files</li>
            <li><strong>Selective Deletion</strong>: Choose what to keep when deleting recordings</li>
        </ul>

        <h3>Location Intelligence</h3>
        <ul>
            <li><strong>GPS Integration</strong>: Automatic location capture</li>
            <li><strong>Reverse Geocoding</strong>: Converts coordinates to addresses</li>
            <li><strong>Smart Location Search</strong>: Advanced search with 3-tier fallback system</li>
            <li><strong>University Database</strong>: Built-in mapping for major universities</li>
            <li><strong>Search Retry Logic</strong>: Intelligent retry for failed searches</li>
            <li><strong>Interactive Maps</strong>: View recording locations</li>
            <li><strong>Manual Location</strong>: Add locations after recording</li>
            <li><strong>Performance Optimized</strong>: Background processing prevents UI blocking</li>
        </ul>

        <h3>Data Migration</h3>
        <ul>
            <li><strong>Legacy Import</strong>: Migrate from old file-based storage</li>
            <li><strong>Data Integrity</strong>: Validate and repair data relationships</li>
            <li><strong>Batch Operations</strong>: Process multiple files at once</li>
            <li><strong>Progress Tracking</strong>: Monitor migration progress</li>
        </ul>

        <h2 id="best-practices">üéØ Best Practices</h2>

        <h3>Recording</h3>
        <ul>
            <li><strong>Environment</strong>: Record in quiet environments for best quality</li>
            <li><strong>Distance</strong>: Keep microphone 6-12 inches from mouth</li>
            <li><strong>Duration</strong>: Break long recordings into segments</li>
            <li><strong>Background</strong>: Minimize background noise</li>
        </ul>

        <h3>AI Configuration</h3>
        <ul>
            <li><strong>Privacy</strong>: Use local engines for sensitive content</li>
            <li><strong>Cost</strong>: Start with free engines, upgrade as needed</li>
            <li><strong>Quality</strong>: Experiment with different models for best results</li>
            <li><strong>Reliability</strong>: Have backup engines configured</li>
        </ul>

        <h3>Data Management</h3>
        <ul>
            <li><strong>Regular Backups</strong>: Export important recordings</li>
            <li><strong>Cleanup</strong>: Remove old recordings periodically</li>
            <li><strong>Organization</strong>: Use descriptive titles for easy finding</li>
            <li><strong>Metadata</strong>: Add location and custom dates for context</li>
        </ul>

        <h3>Performance</h3>
        <ul>
            <li><strong>Battery</strong>: Use local engines when battery is low</li>
            <li><strong>Storage</strong>: Monitor available space</li>
            <li><strong>Network</strong>: Use local engines when internet is slow</li>
            <li><strong>Memory</strong>: Close other apps during processing</li>
        </ul>

        <h2 id="external-resources">üîó External Resources</h2>

        <h3>AI Service Documentation</h3>
        <ul>
            <li><strong>OpenAI</strong>: <a href="https://platform.openai.com/docs" target="_blank">platform.openai.com/docs</a></li>
            <li><strong>Google AI</strong>: <a href="https://ai.google.dev" target="_blank">ai.google.dev</a></li>
            <li><strong>AWS Bedrock</strong>: <a href="https://docs.aws.amazon.com/bedrock" target="_blank">docs.aws.amazon.com/bedrock</a></li>
            <li><strong>AWS Transcribe</strong>: <a href="https://docs.aws.amazon.com/transcribe" target="_blank">docs.aws.amazon.com/transcribe</a></li>
        </ul>

        <h3>Additional Resources</h3>
        <ul>
            <li><strong>Mistral AI</strong>: <a href="https://docs.mistral.ai" target="_blank">docs.mistral.ai</a></li>
            <li><strong>Ollama</strong>: <a href="https://ollama.com" target="_blank">ollama.com</a></li>
            <li><strong>OpenAI API Compatible</strong>:
                <ul>
                    <li><strong>LiteLLM</strong>: <a href="https://github.com/BerriAI/litellm" target="_blank">github.com/BerriAI/litellm</a></li>
                    <li><strong>llama.cpp</strong>: <a href="https://github.com/ggerganov/llama.cpp" target="_blank">github.com/ggerganov/llama.cpp</a> - Official repository with installation and server setup instructions</li>
                    <li><strong>llama-cpp-python</strong>: <a href="https://llama-cpp-python.readthedocs.io/en/latest/server/" target="_blank">llama-cpp-python.readthedocs.io</a> - Python bindings with server support</li>
                    <li><strong>Nebius</strong>: <a href="https://nebius.com" target="_blank">nebius.com</a></li>
                    <li><strong>Groq</strong>: <a href="https://groq.com" target="_blank">groq.com</a></li>
                </ul>
            </li>
            <li><strong>Whisper</strong>: <a href="https://github.com/ahmetoner/whisper-asr-webservice" target="_blank">github.com/ahmetoner/whisper-asr-webservice</a></li>
            <li><strong>AWS Transcribe</strong>: <a href="https://aws.amazon.com/transcribe/" target="_blank">aws.amazon.com/transcribe/</a></li>
        </ul>

        <h3>Support</h3>
        <ul>
            <li><strong>GitHub Issues</strong>: Report bugs and request features</li>
            <li><strong>Documentation</strong>: Check the README for technical details</li>
            <li><strong>Community</strong>: Join discussions and share tips</li>
        </ul>

        <div class="success-box">
            <h3>üéØ Ready to Get Started?</h3>
            <p><strong>BisonNotes AI</strong> - Transform your spoken words into actionable intelligence with advanced AI processing and comprehensive data management.</p>
            <p>Download the app and start recording your first BisonNotes today!</p>
        </div>

        <hr style="margin: 3em 0; border: none; border-top: 2px solid currentColor;">

        <p style="text-align: center; font-size: 0.9em; opacity: 0.7;">
            <em>This documentation is regularly updated. For the latest information, check the app's built-in help or visit our support resources.</em>
        </p>
    </div>
</body>
</html>
